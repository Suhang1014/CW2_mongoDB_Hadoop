{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coursework 2: Data Processing\n",
    "\n",
    "## Task 1\n",
    "This coursework will assess your understanding of using NoSQL to store and retrieve data.  You will perform operations on data from the Enron email dataset in a MongoDB database, and write a report detailing the suitability of different types of databases for data science applications.  You will be required to run code to answer the given questions in the Jupyter notebook provided, and write a report describing alternative approaches to using MongoDB.\n",
    "\n",
    "Download the JSON version of the Enron data (using the “Download as zip” to download the data file from http://edshare.soton.ac.uk/19548/, the file is about 380MB) and import into a collection called messages in a database called enron.  You do not need to set up any authentication.  In the Jupyter notebook provided, perform the following tasks, using the Python PyMongo library.\n",
    "\n",
    "Answers should be efficient in terms of speed.  Answers which are less efficient will not get full marks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I used MongoDB v4.0.3 in this coursework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "from datetime import datetime\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%bash\n",
    "# mongoimport --db enron --collection messages --file ./data/messages.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1)\n",
    "Write a function which returns a MongoDB connection object to the \"messages\" collection. [4 points] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "get_collection",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def get_collection():\n",
    "    \"\"\"\n",
    "    Connects to the server, and returns a collection object\n",
    "    of the `messages` collection in the `enron` database\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    client = MongoClient('mongodb://localhost:27017')\n",
    "    db = client.enron\n",
    "    collection = db.messages\n",
    "\n",
    "    return collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = get_collection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2)\n",
    "\n",
    "Write a function which returns the amount of emails in the messages collection in total. [4 points] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "get_amount_of_messages",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def get_amount_of_messages(collection):\n",
    "    \"\"\"\n",
    "    :param collection A PyMongo collection object\n",
    "    :return the amount of documents in the collection\n",
    "    \"\"\"    \n",
    "    # YOUR CODE HERE\n",
    "    messages_amount = collection.count_documents({})\n",
    "    \n",
    "    return messages_amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of messages is:  501513\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "messages_amount = get_amount_of_messages(collection)\n",
    "print('The amount of messages is: ', messages_amount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) \n",
    "\n",
    "Write a function which returns each person who was BCCed on an email.  Include each person only once, and display only their name according to the X-To header. [4 points] \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "get_bcced_people",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def get_bcced_people(collection):\n",
    "    \"\"\"\n",
    "    :param collection A PyMongo collection object\n",
    "    :return the names of the people who have received an email by BCC\n",
    "    \"\"\"    \n",
    "    # YOUR CODE HERE\n",
    "    filter = {'headers.Bcc' : {'$exists' : True}}\n",
    "    cursor = collection.find(filter)\n",
    "    names = cursor.distinct('headers.X-bcc')\n",
    "     \n",
    "    bcced_people = set([])\n",
    "    for name in names:\n",
    "        if name != '':\n",
    "            name = name.split('>,')\n",
    "            for item in name:\n",
    "                if item != '':\n",
    "                    pattern = re.compile(r'[a-zA-Z, .]+')\n",
    "                    item = pattern.match(item).group(0).strip()\n",
    "                    bcced_people.add(item)\n",
    "    \n",
    "    return  bcced_people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of people Bcc'ed:  58 \n",
      "\n",
      "{'Arora, Harry',\n",
      " 'Audrey Robertson',\n",
      " 'Barrow, Cynthia',\n",
      " 'Batista, Daniel',\n",
      " 'Beck, Sally',\n",
      " 'Benson, Robert',\n",
      " 'Beth Apollo',\n",
      " 'Carr, James',\n",
      " 'Castano, Marianne',\n",
      " 'Cebryk, Doug',\n",
      " 'Choate, Heather',\n",
      " 'Daily, Pamela',\n",
      " 'Davis, Mark Dana',\n",
      " 'Denny, Jennifer',\n",
      " 'Dinari, Sabra L.',\n",
      " 'Eisenstein, Arnold L.',\n",
      " 'Ellenberg, Mark',\n",
      " 'Evans, Carolyn',\n",
      " 'Gadd, Eric',\n",
      " 'Germany, Chris',\n",
      " 'Gray, Barbara N.',\n",
      " 'Greg Piper',\n",
      " 'Harris, Steven',\n",
      " 'Heard, Marie',\n",
      " 'Issler, Paulo',\n",
      " 'Jason Sokolov',\n",
      " 'Joannie Williamson',\n",
      " 'Kaminski, Vince J',\n",
      " 'Kilmer III, Robert',\n",
      " 'Lagrasta, Fred',\n",
      " 'Lay, Kenneth',\n",
      " 'Lee, Bob',\n",
      " 'Majed Nachawati',\n",
      " 'Margaret Daffin',\n",
      " 'Mark Breese',\n",
      " 'Mark Palmer',\n",
      " 'Palmer, Mark A.',\n",
      " 'Parks, Joe',\n",
      " 'Patti Thompson',\n",
      " 'Phil Lowry',\n",
      " 'Rahaim, Christian',\n",
      " 'Ratliff, Dale',\n",
      " 'Robertson, Audrey',\n",
      " 'Sanchez, Christina',\n",
      " 'Schaffer, Brian',\n",
      " 'Schoolcraft, Darrell',\n",
      " 'Schwieger, Jim',\n",
      " 'Steve Hotte',\n",
      " 'Steven J Kean',\n",
      " 'Storey, Geoff',\n",
      " 'Sturm, Fletcher J.',\n",
      " 'Taylor, Mark E',\n",
      " 'VideoConference',\n",
      " 'Whalley, Greg',\n",
      " 'Wright, Alice',\n",
      " 'cannon',\n",
      " 'daveike',\n",
      " 'demianen'}\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "bcced_people = get_bcced_people(collection)\n",
    "print('Number of people Bcc\\'ed: ',len(bcced_people),'\\n')\n",
    "pprint(bcced_people)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4)\n",
    "\n",
    "Write a function with parameter subject, which gets all emails in a thread with that parameter, and orders them by date (ascending). “An email thread is an email message that includes a running list of all the succeeding replies starting with the original email.”, check for detail descriptions at https://www.techopedia.com/definition/1503/email-thread [4 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "get_emails_in_thread",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def get_emails_in_thread(collection, subject):\n",
    "    \"\"\"\n",
    "    :param collection A PyMongo collection object\n",
    "    :return All emails in the thread with that subject\n",
    "    \"\"\"    \n",
    "    # YOUR CODE HERE\n",
    "    match = {\n",
    "        \"$match\":{\n",
    "            \"headers.Subject\" :\n",
    "            {\"$regex\": subject}\n",
    "        }\n",
    "    }\n",
    "    project = {\n",
    "        \"$addFields\":\n",
    "            {\n",
    "                \"new_date\":{\n",
    "                    \"$dateFromString\":{\n",
    "                        \"dateString\": {\"$substr\":[\"$headers.Date\", 0, 30]}\n",
    "                        }\n",
    "                    }\n",
    "            }\n",
    "    }\n",
    "    sort = {\n",
    "        \"$sort\": {\n",
    "            \"new_date\": pymongo.ASCENDING\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    cursor = collection.aggregate([match,project,sort])\n",
    "    \n",
    "    return cursor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('4f16fc98d1e2d3237100435a'),\n",
      " 'body': 'http://www.telski.com/tandp/extras/photo_of_day/index.html',\n",
      " 'filename': '76.',\n",
      " 'headers': {'Content-Transfer-Encoding': '7bit',\n",
      "             'Content-Type': 'text/plain; charset=us-ascii',\n",
      "             'Date': 'Tue, 14 Nov 2000 07:09:00 -0800 (PST)',\n",
      "             'From': 'eric.bass@enron.com',\n",
      "             'Message-ID': '<27972472.1075854684357.JavaMail.evans@thyme>',\n",
      "             'Mime-Version': '1.0',\n",
      "             'Subject': 'check it out',\n",
      "             'To': 'shanna.husser@enron.com, '\n",
      "                   'dfranklin@hanovermeasurement.com, \\r\\n'\n",
      "                   '\\tjason.bass2@compaq.com, daphneco64@bigplanet.com, \\r\\n'\n",
      "                   '\\tlwbthemarine@bigplanet.com',\n",
      "             'X-FileName': 'ebass.nsf',\n",
      "             'X-Folder': '\\\\Eric_Bass_Dec2000\\\\Notes Folders\\\\Sent',\n",
      "             'X-From': 'Eric Bass',\n",
      "             'X-Origin': 'Bass-E',\n",
      "             'X-To': 'Shanna Husser, dfranklin@hanovermeasurement.com, '\n",
      "                     'Jason.Bass2@COMPAQ.com, daphneco64@bigplanet.com, '\n",
      "                     'lwbthemarine@bigplanet.com',\n",
      "             'X-bcc': '',\n",
      "             'X-cc': ''},\n",
      " 'mailbox': 'bass-e',\n",
      " 'new_date': datetime.datetime(2000, 11, 14, 8, 29),\n",
      " 'subFolder': 'sent'}\n",
      "{'_id': ObjectId('4f16fc97d1e2d32371003e29'),\n",
      " 'body': \"I'm ready, are you?  Did you get my message about Dad?  I don't want \"\n",
      "         'you to\\n'\n",
      "         'worry but he will have to be in bed with his leg elevated for a '\n",
      "         'week.  Send\\n'\n",
      "         'him a nice note, o.k?\\n'\n",
      "         '----- Original Message -----\\n'\n",
      "         'From: <Eric.Bass@enron.com>\\n'\n",
      "         'To: <shusser@enron.com>; <dfranklin@hanovermeasurement.com>;\\n'\n",
      "         '<Jason.Bass2@COMPAQ.com>; <daphneco64@bigplanet.com>;\\n'\n",
      "         '<lwbthemarine@bigplanet.com>\\n'\n",
      "         'Sent: Tuesday, November 14, 2000 3:09 PM\\n'\n",
      "         'Subject: check it out\\n'\n",
      "         '\\n'\n",
      "         '\\n'\n",
      "         '> http://www.telski.com/tandp/extras/photo_of_day/index.html\\n'\n",
      "         '>',\n",
      " 'filename': '452.',\n",
      " 'headers': {'Bcc': 'jason.bass2@compaq.com',\n",
      "             'Cc': 'jason.bass2@compaq.com',\n",
      "             'Content-Transfer-Encoding': '7bit',\n",
      "             'Content-Type': 'text/plain; charset=us-ascii',\n",
      "             'Date': 'Tue, 14 Nov 2000 07:25:00 -0800 (PST)',\n",
      "             'From': 'daphneco64@bigplanet.com',\n",
      "             'Message-ID': '<24383193.1075854677459.JavaMail.evans@thyme>',\n",
      "             'Mime-Version': '1.0',\n",
      "             'Subject': 'Re: check it out',\n",
      "             'To': 'eric.bass@enron.com',\n",
      "             'X-FileName': 'ebass.nsf',\n",
      "             'X-Folder': '\\\\Eric_Bass_Dec2000\\\\Notes Folders\\\\Notes inbox',\n",
      "             'X-From': '\"K. Bass\" <daphneco64@bigplanet.com>',\n",
      "             'X-Origin': 'Bass-E',\n",
      "             'X-To': 'Eric.Bass@enron.com',\n",
      "             'X-bcc': '',\n",
      "             'X-cc': '\"Bass, Jason\" <Jason.Bass2@COMPAQ.com>'},\n",
      " 'mailbox': 'bass-e',\n",
      " 'new_date': datetime.datetime(2000, 11, 14, 8, 45),\n",
      " 'subFolder': 'notes_inbox'}\n",
      "{'_id': ObjectId('4f16fd8bd1e2d3237104925d'),\n",
      " 'body': 'http://www.victoria-house.com/lovers.html\\n\\nthen browse!',\n",
      " 'filename': '121.',\n",
      " 'headers': {'Content-Transfer-Encoding': '7bit',\n",
      "             'Content-Type': 'text/plain; charset=us-ascii',\n",
      "             'Date': 'Fri, 1 Jun 2001 02:24:00 -0700 (PDT)',\n",
      "             'From': 'kay.mann@enron.com',\n",
      "             'Message-ID': '<12900112.1075846031166.JavaMail.evans@thyme>',\n",
      "             'Mime-Version': '1.0',\n",
      "             'Subject': 'check it out',\n",
      "             'To': 'nmann@erac.com',\n",
      "             'X-FileName': 'kmann.nsf',\n",
      "             'X-Folder': \"\\\\Kay_Mann_June2001_4\\\\Notes Folders\\\\'sent mail\",\n",
      "             'X-From': 'Kay Mann',\n",
      "             'X-Origin': 'MANN-K',\n",
      "             'X-To': 'nmann@erac.com',\n",
      "             'X-bcc': '',\n",
      "             'X-cc': ''},\n",
      " 'mailbox': 'mann-k',\n",
      " 'new_date': datetime.datetime(2001, 6, 1, 9, 24),\n",
      " 'subFolder': '_sent_mail'}\n",
      "{'_id': ObjectId('4f16fd93d1e2d3237104b8d4'),\n",
      " 'body': 'http://www.victoria-house.com/lovers.html\\n\\nthen browse!',\n",
      " 'filename': '6307.',\n",
      " 'headers': {'Content-Transfer-Encoding': '7bit',\n",
      "             'Content-Type': 'text/plain; charset=us-ascii',\n",
      "             'Date': 'Fri, 1 Jun 2001 02:24:00 -0700 (PDT)',\n",
      "             'From': 'kay.mann@enron.com',\n",
      "             'Message-ID': '<21705033.1075845734363.JavaMail.evans@thyme>',\n",
      "             'Mime-Version': '1.0',\n",
      "             'Subject': 'check it out',\n",
      "             'To': 'nmann@erac.com',\n",
      "             'X-FileName': 'kmann.nsf',\n",
      "             'X-Folder': '\\\\Kay_Mann_June2001_1\\\\Notes Folders\\\\All documents',\n",
      "             'X-From': 'Kay Mann',\n",
      "             'X-Origin': 'MANN-K',\n",
      "             'X-To': 'nmann@erac.com',\n",
      "             'X-bcc': '',\n",
      "             'X-cc': ''},\n",
      " 'mailbox': 'mann-k',\n",
      " 'new_date': datetime.datetime(2001, 6, 1, 9, 24),\n",
      " 'subFolder': 'all_documents'}\n",
      "{'_id': ObjectId('4f16fd97d1e2d3237104cd95'),\n",
      " 'body': 'http://www.victoria-house.com/lovers.html\\n\\nthen browse!',\n",
      " 'filename': '4619.',\n",
      " 'headers': {'Content-Transfer-Encoding': '7bit',\n",
      "             'Content-Type': 'text/plain; charset=us-ascii',\n",
      "             'Date': 'Fri, 1 Jun 2001 02:24:00 -0700 (PDT)',\n",
      "             'From': 'kay.mann@enron.com',\n",
      "             'Message-ID': '<5664762.1075845868302.JavaMail.evans@thyme>',\n",
      "             'Mime-Version': '1.0',\n",
      "             'Subject': 'check it out',\n",
      "             'To': 'nmann@erac.com',\n",
      "             'X-FileName': 'kmann.nsf',\n",
      "             'X-Folder': '\\\\Kay_Mann_June2001_2\\\\Notes Folders\\\\Discussion '\n",
      "                         'threads',\n",
      "             'X-From': 'Kay Mann',\n",
      "             'X-Origin': 'MANN-K',\n",
      "             'X-To': 'nmann@erac.com',\n",
      "             'X-bcc': '',\n",
      "             'X-cc': ''},\n",
      " 'mailbox': 'mann-k',\n",
      " 'new_date': datetime.datetime(2001, 6, 1, 9, 24),\n",
      " 'subFolder': 'discussion_threads'}\n",
      "{'_id': ObjectId('4f16fd9dd1e2d3237104e799'),\n",
      " 'body': 'http://www.victoria-house.com/lovers.html\\n\\nthen browse!',\n",
      " 'filename': '4327.',\n",
      " 'headers': {'Content-Transfer-Encoding': '7bit',\n",
      "             'Content-Type': 'text/plain; charset=us-ascii',\n",
      "             'Date': 'Fri, 1 Jun 2001 02:24:00 -0700 (PDT)',\n",
      "             'From': 'kay.mann@enron.com',\n",
      "             'Message-ID': '<265601.1075846025235.JavaMail.evans@thyme>',\n",
      "             'Mime-Version': '1.0',\n",
      "             'Subject': 'check it out',\n",
      "             'To': 'nmann@erac.com',\n",
      "             'X-FileName': 'kmann.nsf',\n",
      "             'X-Folder': '\\\\Kay_Mann_June2001_3\\\\Notes Folders\\\\Sent',\n",
      "             'X-From': 'Kay Mann',\n",
      "             'X-Origin': 'MANN-K',\n",
      "             'X-To': 'nmann@erac.com',\n",
      "             'X-bcc': '',\n",
      "             'X-cc': ''},\n",
      " 'mailbox': 'mann-k',\n",
      " 'new_date': datetime.datetime(2001, 6, 1, 9, 24),\n",
      " 'subFolder': 'sent'}\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "subject = 'check it out'\n",
    "emails_by_subject = get_emails_in_thread(collection, subject)\n",
    "# print(len(emails_by_subject), ' results.\\n')\n",
    "for item in emails_by_subject:\n",
    "    pprint(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5)\n",
    "\n",
    "Write a function which returns the percentage of emails sent on a weekend (i.e., Saturday and Sunday) as a `float` between 0 and 1. [6 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "get_percentage_sent_on_weekend",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def get_percentage_sent_on_weekend(collection):\n",
    "    \"\"\"\n",
    "    :param collection A PyMongo collection object\n",
    "    :return A float between 0 and 1\n",
    "    \"\"\"    \n",
    "    # YOUR CODE HERE\n",
    "    filter = {'headers.Date' : {'$regex' : '^(Sat|Sun)'}}\n",
    "    num_sent_on_weekend = collection.count_documents(filter)\n",
    "    num_sum = collection.count_documents({})\n",
    "    percentage = num_sent_on_weekend / num_sum\n",
    "    \n",
    "    return percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage sent on weekend is:  0.04005479419277267\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "percentage_sent_on_weekend = get_percentage_sent_on_weekend(collection)\n",
    "print('Percentage sent on weekend is: ', percentage_sent_on_weekend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6)\n",
    "\n",
    "Write a function with parameter limit. The function should return for each email account: the number of emails sent, the number of emails received, and the total number of emails (sent and received). Use the following format: [{\"contact\": \"michael.simmons@enron.com\", \"from\": 42, \"to\": 92, \"total\": 134}] and the information contained in the To, From, and Cc headers. Sort the output in descending order by the total number of emails. Use the parameter limit to specify the number of results to be returned. If limit is null, the function should return all results. If limit is higher than null, the function should return the number of results specified as limit. limit cannot take negative values. [10 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "get_emails_between_contacts",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def get_emails_between_contacts(collection,limit):\n",
    "    \"\"\"\n",
    "    Shows the communications between contacts\n",
    "    Sort by the descending order of total emails using the To, From, and Cc headers.\n",
    "    :param `collection` A PyMongo collection object    \n",
    "    :param `limit` An integer specifying the amount to display, or\n",
    "    if null will display all outputs\n",
    "    :return A list of objects of the form:\n",
    "    [{\n",
    "        'contact': <<Another email address>>\n",
    "        'from': \n",
    "        'to': \n",
    "        'total': \n",
    "    },{.....}]\n",
    "    \"\"\"    \n",
    "    # YOUR CODE HERE\n",
    "    # Project\n",
    "    project = {\n",
    "        '$project':{\n",
    "            \"From\": \"$headers.From\",\n",
    "            \"To\": {\"$split\":[\"$headers.To\", \",\"]},\n",
    "            \"Cc\": {\"$split\":[\"$headers.Cc\", \",\"]}\n",
    "            }\n",
    "     }\n",
    "    unwind_to = {\n",
    "         \"$unwind\":\"$To\"\n",
    "         }\n",
    "    unwind_cc = {\n",
    "         \"$unwind\":\"$Cc\"\n",
    "         }\n",
    "    # number of from\n",
    "    group_from = {\n",
    "        \"$group\":{\n",
    "            \"_id\": \"$From\",\n",
    "            \"from\": {\"$sum\":1}\n",
    "        }\n",
    "    }\n",
    "    num_from = collection.aggregate([project,group_from])\n",
    "    # Number of To\n",
    "    group_to = {\n",
    "         \"$group\": {\n",
    "             \"_id\": {\"$trim\":{\"input\":\"$To\"}},\n",
    "             \"to\": {\"$sum\":1}\n",
    "        }\n",
    "    }\n",
    "    num_to = collection.aggregate([project,unwind_to,group_to])\n",
    "    # Number of Cc\n",
    "    group_cc = {\n",
    "        \"$group\":{\n",
    "            \"_id\": {\"$trim\":{\"input\":\"$Cc\"}},\n",
    "            \"cc\": {\"$sum\":1}\n",
    "        }\n",
    "    }\n",
    "    num_cc = collection.aggregate([project,unwind_cc,group_cc])\n",
    "    \n",
    "    df_from = pd.DataFrame(list(num_from))\n",
    "    df_to = pd.DataFrame(list(num_to))\n",
    "    df_cc = pd.DataFrame(list(num_cc))\n",
    "    \n",
    "    \n",
    "    df_merge = df_from.merge(df_to,how='outer').merge(df_cc,how='outer').head(limit)\n",
    "    df_merge.fillna(0,inplace=True)\n",
    "    df_merge['to'] = df_merge['to'] + df_merge['cc']\n",
    "    col_total = df_merge['to'] + df_merge['from']\n",
    "    df_merge['total'] = col_total\n",
    "    df_merge.rename(columns={'_id':'contact'}, inplace=True)\n",
    "    df_merge.drop(['cc'],axis=1,inplace=True)\n",
    "    \n",
    "    result = []\n",
    "    for index, row in df_merge.iterrows():\n",
    "        item = {}\n",
    "        item['contact'] = row['contact']\n",
    "        item['from'] = row['from']\n",
    "        item['to'] = row['to']\n",
    "        item['total'] = row['total']\n",
    "        result.append(item)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'contact': 'edwardc38@hotmail.com', 'from': 1.0, 'to': 0.0, 'total': 1.0}\n",
      "{'contact': 'carol.moline@powerpool.ab.ca', 'from': 11.0, 'to': 1.0, 'total': 12.0}\n",
      "{'contact': 'lebend@tdbank.ca', 'from': 1.0, 'to': 0.0, 'total': 1.0}\n",
      "{'contact': 'ingjald@shaw.ca', 'from': 1.0, 'to': 0.0, 'total': 1.0}\n",
      "{'contact': '6.1132.6c-af5ssclxjfagjsrr.1@mail3.travelocity.com', 'from': 1.0, 'to': 0.0, 'total': 1.0}\n",
      "{'contact': 'livia_zufferli@monitor.com', 'from': 4.0, 'to': 23.0, 'total': 27.0}\n",
      "{'contact': 'daemon.extra@enron.com', 'from': 7.0, 'to': 0.0, 'total': 7.0}\n",
      "{'contact': 'ben.sturgeon@gfinet.co.uk', 'from': 1.0, 'to': 1.0, 'total': 2.0}\n",
      "{'contact': 'robert.anderson@blakes.com', 'from': 1.0, 'to': 4.0, 'total': 5.0}\n",
      "{'contact': 'davidpsmith@att.net', 'from': 2.0, 'to': 0.0, 'total': 2.0}\n",
      "{'contact': 'rbhattacharya@velaw.com', 'from': 3.0, 'to': 3.0, 'total': 6.0}\n",
      "{'contact': 'jrogers@mofo.com', 'from': 3.0, 'to': 1.0, 'total': 4.0}\n",
      "{'contact': 'alexeaton@msn.com', 'from': 1.0, 'to': 3.0, 'total': 4.0}\n",
      "{'contact': 'lottyplace@yahoo.com', 'from': 3.0, 'to': 9.0, 'total': 12.0}\n",
      "{'contact': 'jwolf@regenthotels.com', 'from': 1.0, 'to': 2.0, 'total': 3.0}\n",
      "{'contact': 'edmundg@manfinancial.com', 'from': 3.0, 'to': 2.0, 'total': 5.0}\n",
      "{'contact': 'jeffrey.sprecher@intcx.com', 'from': 1.0, 'to': 2.0, 'total': 3.0}\n",
      "{'contact': 'jeffrey.hammad@enron.com', 'from': 1.0, 'to': 14.0, 'total': 15.0}\n",
      "{'contact': 'kenny.w.baldwin@accenture.com', 'from': 1.0, 'to': 11.0, 'total': 12.0}\n",
      "{'contact': 'group.enron@enron.com', 'from': 1.0, 'to': 198.0, 'total': 199.0}\n"
     ]
    }
   ],
   "source": [
    "limit = 20\n",
    "result = get_emails_between_contacts(collection,limit)\n",
    "for item in result:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7)\n",
    "Write a function to find out the number of senders who were also direct receivers. Direct receiver means the email is sent to the person directly, not via cc or bcc. [4 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_from_to_people(collection):\n",
    "    \"\"\"\n",
    "    :param collection A PyMongo collection object\n",
    "    :return the NUMBER of the people who have sent emails and received emails as direct receivers.\n",
    "    \"\"\"    \n",
    "    # YOUR CODE HERE\n",
    "    # From\n",
    "    project_from = {\n",
    "        '$project':{\n",
    "            \"From\": \"$headers.From\"\n",
    "            }\n",
    "     }\n",
    "    group_from = {\n",
    "        '$group':{\n",
    "            '_id':{'$trim':{'input':'$From'}}\n",
    "        }\n",
    "    }\n",
    "    people_from = collection.aggregate([project_from, group_from])\n",
    "    # To\n",
    "    project_to = {\n",
    "        '$project':{\n",
    "            \"To\": {\"$split\":[\"$headers.To\", \",\"]}\n",
    "        }\n",
    "    }\n",
    "    unwind_to = {\n",
    "         \"$unwind\":\"$To\"\n",
    "         }\n",
    "    group_to = {\n",
    "        '$group':{\n",
    "            '_id':{'$trim':{'input':'$To'}}\n",
    "        }\n",
    "    }\n",
    "    people_to = collection.aggregate([project_to,unwind_to,group_to])\n",
    "    # Store them into df\n",
    "    df_from = pd.DataFrame(list(people_from))\n",
    "    df_to = pd.DataFrame(list(people_to))\n",
    "    \n",
    "    df_merge = pd.merge(df_from,df_to,left_on='_id',right_on='_id',how='inner')\n",
    "    \n",
    "    return df_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of users who are sender and direct receivers is:  10590\n"
     ]
    }
   ],
   "source": [
    "results = get_from_to_people(collection)\n",
    "print('The number of users who are sender and direct receivers is: ', results.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8)\n",
    "Write a function with parameters start_date and end_date, which returns the number of email messages that have been sent between those specified dates, including start_date and end_date [4 points] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emails_between_dates(collection, start_date, end_date):\n",
    "    \"\"\"\n",
    "    :param collection A PyMongo collection object\n",
    "    :return All emails between the specified start_date and end_date\n",
    "    \"\"\"    \n",
    "    # YOUR CODE HERE\n",
    "    start_date = start_date + ' 00:00:00'\n",
    "    end_date = end_date + ' 23:59:59'\n",
    "    start_date = datetime.strptime(start_date, '%Y-%m-%d %H:%M:%S')\n",
    "    end_date = datetime.strptime(end_date, '%Y-%m-%d %H:%M:%S')\n",
    "    filter = [\n",
    "    {\n",
    "        \"$project\":\n",
    "            {\n",
    "                \"new_date\":{\n",
    "                    \"$dateFromString\":{\n",
    "                        \"dateString\": {\"$substr\":[\"$headers.Date\", 0, 30]},\n",
    "                        \"onError\":\"\"\n",
    "                        }\n",
    "                    }\n",
    "            }\n",
    "    },\n",
    "    {\n",
    "        '$project':{\n",
    "            'result':{\n",
    "                '$and':[\n",
    "                    {'$gte':['$new_date', start_date]},\n",
    "                    {'$lte':['$new_date', end_date]}\n",
    "                ]\n",
    "                }\n",
    "            }\n",
    "     },\n",
    "    {\n",
    "         '$group':{\n",
    "             '_id':'$result',\n",
    "             'num':{\n",
    "                 '$sum': 1\n",
    "                 }\n",
    "             }\n",
    "         }\n",
    "    ]\n",
    "    \n",
    "    cursor = collection.aggregate(filter)\n",
    "    num = 0\n",
    "    for c in cursor:\n",
    "        if c['_id'] == True:\n",
    "            num = c['num']\n",
    "    return num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of emails between given dates is:  453384\n"
     ]
    }
   ],
   "source": [
    "start_date = '2000-01-01'\n",
    "end_date = '2001-12-30'\n",
    "num = get_emails_between_dates(collection,start_date,end_date)\n",
    "print('The number of emails between given dates is: ', num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "This task will assess your ability to use the Hadoop Streaming API and MapReduce to process data. For each of the questions below, you are expected to write two python scripts, one for the Map phase and one for the Reduce phase. You are also expected to provide the correct parameters to the `hadoop` command to run the MapReduce process. Write down your answers in the specified cells below.\n",
    "\n",
    "To get started, you need to download and unzip the YouTube dataset (available at http://edshare.soton.ac.uk/19547/) onto the machine where you have Hadoop installed (this should be the virtual machine provided).\n",
    "\n",
    "To help you, `%%writefile` has been added to the top of the cells, automatically writing them to \"mapper.py\" and \"reducer.py\" respectively when the cells are run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) \n",
    "Using Youtube01-Psy.csv, find the hourly interval in which most spam was sent. The output should be in the form of a single key-value pair, where the value is a datetime at the start of the hour with the highest number of spam comments. [9 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMMENT_ID,AUTHOR,DATE,CONTENT,CLASS\n",
      "LZQPQhLyRh80UYxNuaDWhIGQYNQ96IuCg-AYWqNPjpU,Julius NM,2013-11-07T06:20:48,\"Huh, anyway check out this you[tube] channel: kobyoshi02\",1\n",
      "LZQPQhLyRh_C2cTtd9MvFRJedxydaVW-2sNg5Diuo4A,adam riyati,2013-11-07T12:37:15,\"Hey guys check out my new channel and our first vid THIS IS US THE  MONKEYS!!! I'm the monkey in the white shirt,please leave a like comment  and please subscribe!!!!\",1\n",
      "LZQPQhLyRh9MSZYnf8djyk0gEF9BHDPYrrK-qCczIY8,Evgeny Murashkin,2013-11-08T17:34:21,just for test I have to say murdev.com,1\n",
      "z13jhp0bxqncu512g22wvzkasxmvvzjaz04,ElNino Melendez,2013-11-09T08:28:43,me shaking my sexy ass on my channel enjoy ^_^ ﻿,1\n",
      "z13fwbwp1oujthgqj04chlngpvzmtt3r3dw,GsMega,2013-11-10T16:05:38,watch?v=vtaRGgvGtWQ   Check this out .﻿,1\n",
      "LZQPQhLyRh9-wNRtlZDM90f1k0BrdVdJyN_YsaSwfxc,Jason Haddad,2013-11-26T02:55:11,\"Hey, check out my new website!! This site is about kids stuff. kidsmediausa  . com\",1\n",
      "z13lfzdo5vmdi1cm123te5uz2mqig1brz04,ferleck ferles,2013-11-27T21:39:24,Subscribe to my channel ﻿,1\n",
      "z122wfnzgt30fhubn04cdn3xfx2mxzngsl40k,Bob Kanowski,2013-11-28T12:33:27,i turned it on mute as soon is i came on i just wanted to check the  views...﻿,0\n",
      "z13ttt1jcraqexk2o234ghbgzxymz1zzi04,Cony,2013-11-28T16:01:47,You should check my channel for Funny VIDEOS!!﻿,1\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "head -n 10 Youtube01-Psy.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mapper.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mapper.py\n",
    "#!/usr/bin/env python\n",
    "#Answer for mapper.py\n",
    "import csv\n",
    "import sys\n",
    "import re\n",
    "\n",
    "lines = sys.stdin.readlines()\n",
    "csvreader = csv.reader(lines)\n",
    "header = next(csvreader)\n",
    "        \n",
    "times = [row[2] for row in csvreader if row[4]=='1']\n",
    "\n",
    "for time in times:\n",
    "    token = re.split(\":\", time)[0]\n",
    "    print(token + \"\\t1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting reducer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile reducer.py\n",
    "#!/usr/bin/env python\n",
    "#Answer for reducer.py\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "\n",
    "input_pairs = sys.stdin.readlines()\n",
    "accumulator = defaultdict(lambda: 0)\n",
    "\n",
    "for row in input_pairs:\n",
    "    key_value_pair = row.split(\"\\t\", 1)\n",
    "    if len(key_value_pair) != 2:\n",
    "        continue\n",
    "        \n",
    "    time = key_value_pair[0]\n",
    "    count = int(key_value_pair[1].strip())\n",
    "    accumulator[time] = accumulator[time] + count\n",
    "\n",
    "for (key, value) in accumulator.items():\n",
    "    print(key + \":00:00\" + \"\\t\" + str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013-11-07T06:00:00\t1\n",
      "2013-11-07T12:00:00\t1\n",
      "2013-11-08T17:00:00\t1\n",
      "2013-11-09T08:00:00\t1\n",
      "2013-11-10T16:00:00\t1\n",
      "2013-11-26T02:00:00\t1\n",
      "2013-11-27T21:00:00\t1\n",
      "2013-11-28T16:00:00\t2\n",
      "2013-11-28T17:00:00\t3\n",
      "2013-11-28T18:00:00\t1\n",
      "2013-11-28T19:00:00\t1\n",
      "2013-11-28T21:00:00\t2\n",
      "2013-11-28T23:00:00\t1\n",
      "2013-11-29T00:00:00\t1\n",
      "2013-12-01T01:00:00\t1\n",
      "2013-12-01T03:00:00\t1\n",
      "2013-12-23T12:00:00\t1\n",
      "2013-12-25T19:00:00\t1\n",
      "2013-12-27T23:00:00\t1\n",
      "2014-01-19T00:00:00\t2\n",
      "2014-01-19T04:00:00\t1\n",
      "2014-01-19T08:00:00\t1\n",
      "2014-01-19T10:00:00\t1\n",
      "2014-01-19T16:00:00\t1\n",
      "2014-01-19T17:00:00\t2\n",
      "2014-01-19T19:00:00\t1\n",
      "2014-01-20T02:00:00\t1\n",
      "2014-01-20T04:00:00\t1\n",
      "2014-01-20T06:00:00\t2\n",
      "2014-01-20T09:00:00\t1\n",
      "2014-01-20T10:00:00\t1\n",
      "2014-01-20T15:00:00\t1\n",
      "2014-01-20T16:00:00\t1\n",
      "2014-01-20T17:00:00\t2\n",
      "2014-01-20T18:00:00\t1\n",
      "2014-01-20T20:00:00\t3\n",
      "2014-01-20T21:00:00\t1\n",
      "2014-11-02T00:00:00\t1\n",
      "2014-11-02T01:00:00\t1\n",
      "2014-11-02T05:00:00\t1\n",
      "2014-11-02T12:00:00\t1\n",
      "2014-11-02T14:00:00\t2\n",
      "2014-11-02T15:00:00\t1\n",
      "2014-11-02T16:00:00\t1\n",
      "2014-11-02T17:00:00\t1\n",
      "2014-11-02T18:00:00\t1\n",
      "2014-11-02T23:00:00\t1\n",
      "2014-11-03T14:00:00\t1\n",
      "2014-11-03T17:00:00\t1\n",
      "2014-11-03T20:00:00\t1\n",
      "2014-11-03T21:00:00\t1\n",
      "2014-11-03T22:00:00\t2\n",
      "2014-11-03T23:00:00\t2\n",
      "2014-11-04T00:00:00\t2\n",
      "2014-11-04T02:00:00\t2\n",
      "2014-11-04T03:00:00\t1\n",
      "2014-11-04T11:00:00\t1\n",
      "2014-11-04T13:00:00\t2\n",
      "2014-11-04T14:00:00\t1\n",
      "2014-11-04T18:00:00\t1\n",
      "2014-11-04T19:00:00\t1\n",
      "2014-11-04T20:00:00\t1\n",
      "2014-11-05T00:00:00\t1\n",
      "2014-11-05T01:00:00\t1\n",
      "2014-11-05T15:00:00\t2\n",
      "2014-11-05T16:00:00\t2\n",
      "2014-11-05T20:00:00\t2\n",
      "2014-11-05T21:00:00\t3\n",
      "2014-11-05T22:00:00\t3\n",
      "2014-11-06T01:00:00\t1\n",
      "2014-11-06T02:00:00\t2\n",
      "2014-11-06T03:00:00\t1\n",
      "2014-11-06T04:00:00\t2\n",
      "2014-11-06T05:00:00\t1\n",
      "2014-11-06T09:00:00\t3\n",
      "2014-11-06T13:00:00\t1\n",
      "2014-11-06T15:00:00\t1\n",
      "2014-11-06T16:00:00\t1\n",
      "2014-11-06T17:00:00\t1\n",
      "2014-11-06T18:00:00\t3\n",
      "2014-11-06T19:00:00\t3\n",
      "2014-11-06T20:00:00\t1\n",
      "2014-11-06T22:00:00\t3\n",
      "2014-11-06T23:00:00\t2\n",
      "2014-11-07T01:00:00\t2\n",
      "2014-11-07T08:00:00\t1\n",
      "2014-11-07T09:00:00\t1\n",
      "2014-11-07T12:00:00\t1\n",
      "2014-11-07T13:00:00\t1\n",
      "2014-11-07T14:00:00\t2\n",
      "2014-11-07T17:00:00\t2\n",
      "2014-11-07T18:00:00\t1\n",
      "2014-11-07T19:00:00\t2\n",
      "2014-11-07T21:00:00\t1\n",
      "2014-11-08T02:00:00\t1\n",
      "2014-11-08T03:00:00\t2\n",
      "2014-11-08T04:00:00\t1\n",
      "2014-11-08T05:00:00\t1\n",
      "2014-11-08T06:00:00\t1\n",
      "2014-11-08T08:00:00\t1\n",
      "2014-11-08T10:00:00\t4\n",
      "2014-11-08T11:00:00\t3\n",
      "2014-11-08T12:00:00\t1\n",
      "2014-11-08T13:00:00\t2\n",
      "2014-11-08T15:00:00\t3\n",
      "2014-11-09T04:00:00\t1\n",
      "2014-11-10T17:00:00\t1\n",
      "2014-11-11T22:00:00\t1\n",
      "2014-11-12T00:00:00\t1\n",
      "2014-11-12T01:00:00\t1\n",
      "2014-11-12T05:00:00\t1\n",
      "2014-11-12T07:00:00\t2\n",
      "2014-11-12T09:00:00\t1\n",
      "2014-11-12T14:00:00\t1\n",
      "2014-11-12T17:00:00\t1\n",
      "2014-11-12T20:00:00\t1\n",
      "2014-11-13T00:00:00\t1\n",
      "2014-11-13T02:00:00\t1\n",
      "2014-11-13T07:00:00\t1\n",
      "2014-11-13T15:00:00\t1\n",
      "2014-11-13T21:00:00\t1\n",
      "2014-11-13T22:00:00\t1\n",
      "2014-11-13T23:00:00\t1\n",
      "2014-11-14T00:00:00\t1\n",
      "2014-11-14T11:00:00\t1\n",
      "2015-05-23T13:00:00\t1\n",
      "2015-06-05T14:00:00\t1\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "chmod a+x mapper.py reducer.py\n",
    "cat Youtube01-Psy.csv | ./mapper.py | ./reducer.py | sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hadoop switched to standalone mode.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenJDK Server VM warning: You have loaded library /opt/hadoop-2.8.5/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.\n",
      "It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.\n",
      "18/12/10 09:50:25 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "18/12/10 09:50:26 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id\n",
      "18/12/10 09:50:26 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=\n",
      "18/12/10 09:50:26 INFO jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "18/12/10 09:50:27 INFO mapred.FileInputFormat: Total input files to process : 1\n",
      "18/12/10 09:50:27 INFO mapreduce.JobSubmitter: number of splits:1\n",
      "18/12/10 09:50:27 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local209536761_0001\n",
      "18/12/10 09:50:28 INFO mapred.LocalDistributedCacheManager: Localized file:/home/comp6235/Notebooks/cw2/mapper.py as file:/tmp/hadoop-comp6235/mapred/local/1544435427973/mapper.py\n",
      "18/12/10 09:50:28 INFO mapred.LocalDistributedCacheManager: Localized file:/home/comp6235/Notebooks/cw2/reducer.py as file:/tmp/hadoop-comp6235/mapred/local/1544435427974/reducer.py\n",
      "18/12/10 09:50:28 INFO mapreduce.Job: The url to track the job: http://localhost:8080/\n",
      "18/12/10 09:50:28 INFO mapreduce.Job: Running job: job_local209536761_0001\n",
      "18/12/10 09:50:28 INFO mapred.LocalJobRunner: OutputCommitter set in config null\n",
      "18/12/10 09:50:28 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapred.FileOutputCommitter\n",
      "18/12/10 09:50:28 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "18/12/10 09:50:28 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "18/12/10 09:50:28 INFO mapred.LocalJobRunner: Waiting for map tasks\n",
      "18/12/10 09:50:28 INFO mapred.LocalJobRunner: Starting task: attempt_local209536761_0001_m_000000_0\n",
      "18/12/10 09:50:29 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "18/12/10 09:50:29 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "18/12/10 09:50:29 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "18/12/10 09:50:29 INFO mapred.MapTask: Processing split: file:/home/comp6235/Notebooks/cw2/Youtube01-Psy.csv:0+57438\n",
      "18/12/10 09:50:29 INFO mapred.MapTask: numReduceTasks: 1\n",
      "18/12/10 09:50:29 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "18/12/10 09:50:29 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "18/12/10 09:50:29 INFO mapred.MapTask: soft limit at 83886080\n",
      "18/12/10 09:50:29 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "18/12/10 09:50:29 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "18/12/10 09:50:29 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "18/12/10 09:50:29 INFO streaming.PipeMapRed: PipeMapRed exec [/home/comp6235/Notebooks/cw2/././mapper.py]\n",
      "18/12/10 09:50:29 INFO Configuration.deprecation: mapred.work.output.dir is deprecated. Instead, use mapreduce.task.output.dir\n",
      "18/12/10 09:50:29 INFO Configuration.deprecation: map.input.start is deprecated. Instead, use mapreduce.map.input.start\n",
      "18/12/10 09:50:29 INFO Configuration.deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap\n",
      "18/12/10 09:50:29 INFO Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id\n",
      "18/12/10 09:50:29 INFO Configuration.deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id\n",
      "18/12/10 09:50:29 INFO Configuration.deprecation: mapred.local.dir is deprecated. Instead, use mapreduce.cluster.local.dir\n",
      "18/12/10 09:50:29 INFO Configuration.deprecation: map.input.file is deprecated. Instead, use mapreduce.map.input.file\n",
      "18/12/10 09:50:29 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords\n",
      "18/12/10 09:50:29 INFO Configuration.deprecation: map.input.length is deprecated. Instead, use mapreduce.map.input.length\n",
      "18/12/10 09:50:29 INFO Configuration.deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id\n",
      "18/12/10 09:50:29 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name\n",
      "18/12/10 09:50:29 INFO Configuration.deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition\n",
      "18/12/10 09:50:29 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "18/12/10 09:50:29 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "18/12/10 09:50:29 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "18/12/10 09:50:29 INFO streaming.PipeMapRed: Records R/W=351/1\n",
      "18/12/10 09:50:29 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "18/12/10 09:50:29 INFO streaming.PipeMapRed: mapRedFinished\n",
      "18/12/10 09:50:29 INFO mapred.LocalJobRunner: \n",
      "18/12/10 09:50:29 INFO mapred.MapTask: Starting flush of map output\n",
      "18/12/10 09:50:29 INFO mapred.MapTask: Spilling map output\n",
      "18/12/10 09:50:29 INFO mapred.MapTask: bufstart = 0; bufend = 2800; bufvoid = 104857600\n",
      "18/12/10 09:50:29 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26213700(104854800); length = 697/6553600\n",
      "18/12/10 09:50:29 INFO mapred.MapTask: Finished spill 0\n",
      "18/12/10 09:50:29 INFO mapred.Task: Task:attempt_local209536761_0001_m_000000_0 is done. And is in the process of committing\n",
      "18/12/10 09:50:29 INFO mapred.LocalJobRunner: Records R/W=351/1\n",
      "18/12/10 09:50:29 INFO mapred.Task: Task 'attempt_local209536761_0001_m_000000_0' done.\n",
      "18/12/10 09:50:29 INFO mapred.Task: Final Counters for attempt_local209536761_0001_m_000000_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=192263\n",
      "\t\tFILE: Number of bytes written=519626\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=351\n",
      "\t\tMap output records=175\n",
      "\t\tMap output bytes=2800\n",
      "\t\tMap output materialized bytes=3156\n",
      "\t\tInput split bytes=103\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=175\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=23\n",
      "\t\tTotal committed heap usage (bytes)=137433088\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=57438\n",
      "18/12/10 09:50:29 INFO mapred.LocalJobRunner: Finishing task: attempt_local209536761_0001_m_000000_0\n",
      "18/12/10 09:50:29 INFO mapred.LocalJobRunner: map task executor complete.\n",
      "18/12/10 09:50:29 INFO mapred.LocalJobRunner: Waiting for reduce tasks\n",
      "18/12/10 09:50:29 INFO mapred.LocalJobRunner: Starting task: attempt_local209536761_0001_r_000000_0\n",
      "18/12/10 09:50:29 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "18/12/10 09:50:29 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "18/12/10 09:50:29 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "18/12/10 09:50:29 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1055908\n",
      "18/12/10 09:50:29 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=363285696, maxSingleShuffleLimit=90821424, mergeThreshold=239768576, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "18/12/10 09:50:29 INFO reduce.EventFetcher: attempt_local209536761_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "18/12/10 09:50:29 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local209536761_0001_m_000000_0 decomp: 3152 len: 3156 to MEMORY\n",
      "18/12/10 09:50:29 INFO mapreduce.Job: Job job_local209536761_0001 running in uber mode : false\n",
      "18/12/10 09:50:29 INFO reduce.InMemoryMapOutput: Read 3152 bytes from map-output for attempt_local209536761_0001_m_000000_0\n",
      "18/12/10 09:50:29 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3152, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->3152\n",
      "18/12/10 09:50:29 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "18/12/10 09:50:29 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning\n",
      "18/12/10 09:50:29 INFO mapred.LocalJobRunner: 1 / 1 copied.\n",
      "18/12/10 09:50:29 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
      "18/12/10 09:50:29 INFO mapred.Merger: Merging 1 sorted segments\n",
      "18/12/10 09:50:29 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 3136 bytes\n",
      "18/12/10 09:50:29 INFO reduce.MergeManagerImpl: Merged 1 segments, 3152 bytes to disk to satisfy reduce memory limit\n",
      "18/12/10 09:50:29 INFO reduce.MergeManagerImpl: Merging 1 files, 3156 bytes from disk\n",
      "18/12/10 09:50:29 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce\n",
      "18/12/10 09:50:29 INFO mapred.Merger: Merging 1 sorted segments\n",
      "18/12/10 09:50:29 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 3136 bytes\n",
      "18/12/10 09:50:29 INFO mapred.LocalJobRunner: 1 / 1 copied.\n",
      "18/12/10 09:50:29 INFO streaming.PipeMapRed: PipeMapRed exec [/home/comp6235/Notebooks/cw2/././reducer.py]\n",
      "18/12/10 09:50:29 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "18/12/10 09:50:29 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\n",
      "18/12/10 09:50:29 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "18/12/10 09:50:29 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "18/12/10 09:50:29 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "18/12/10 09:50:29 INFO streaming.PipeMapRed: Records R/W=175/1\n",
      "18/12/10 09:50:29 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "18/12/10 09:50:29 INFO streaming.PipeMapRed: mapRedFinished\n",
      "18/12/10 09:50:29 INFO mapred.Task: Task:attempt_local209536761_0001_r_000000_0 is done. And is in the process of committing\n",
      "18/12/10 09:50:29 INFO mapred.LocalJobRunner: 1 / 1 copied.\n",
      "18/12/10 09:50:29 INFO mapred.Task: Task attempt_local209536761_0001_r_000000_0 is allowed to commit now\n",
      "18/12/10 09:50:29 INFO output.FileOutputCommitter: Saved output of task 'attempt_local209536761_0001_r_000000_0' to file:/home/comp6235/Notebooks/cw2/output/_temporary/0/task_local209536761_0001_r_000000\n",
      "18/12/10 09:50:30 INFO mapred.LocalJobRunner: Records R/W=175/1 > reduce\n",
      "18/12/10 09:50:30 INFO mapred.Task: Task 'attempt_local209536761_0001_r_000000_0' done.\n",
      "18/12/10 09:50:30 INFO mapred.Task: Final Counters for attempt_local209536761_0001_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=198607\n",
      "\t\tFILE: Number of bytes written=525608\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=127\n",
      "\t\tReduce shuffle bytes=3156\n",
      "\t\tReduce input records=175\n",
      "\t\tReduce output records=127\n",
      "\t\tSpilled Records=175\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=4\n",
      "\t\tTotal committed heap usage (bytes)=137433088\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=2826\n",
      "18/12/10 09:50:30 INFO mapred.LocalJobRunner: Finishing task: attempt_local209536761_0001_r_000000_0\n",
      "18/12/10 09:50:30 INFO mapred.LocalJobRunner: reduce task executor complete.\n",
      "18/12/10 09:50:30 INFO mapreduce.Job:  map 100% reduce 100%\n",
      "18/12/10 09:50:30 INFO mapreduce.Job: Job job_local209536761_0001 completed successfully\n",
      "18/12/10 09:50:30 INFO mapreduce.Job: Counters: 30\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=390870\n",
      "\t\tFILE: Number of bytes written=1045234\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=351\n",
      "\t\tMap output records=175\n",
      "\t\tMap output bytes=2800\n",
      "\t\tMap output materialized bytes=3156\n",
      "\t\tInput split bytes=103\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=127\n",
      "\t\tReduce shuffle bytes=3156\n",
      "\t\tReduce input records=175\n",
      "\t\tReduce output records=127\n",
      "\t\tSpilled Records=350\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=27\n",
      "\t\tTotal committed heap usage (bytes)=274866176\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=57438\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=2826\n",
      "18/12/10 09:50:30 INFO streaming.StreamJob: Output directory: output\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "#Hadoop command to run the map reduce.\n",
    "rm -rf output\n",
    "\n",
    "hadoop-standalone-mode.sh\n",
    "\n",
    "hadoop jar $HADOOP_HOME/share/hadoop/tools/lib/hadoop-streaming-*.jar \\\n",
    "-files mapper.py,reducer.py   \\\n",
    "-input Youtube01-Psy.csv   \\\n",
    "-mapper ./mapper.py  \\\n",
    "-reducer ./reducer.py \\\n",
    "-output output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hour_with_most_spam\t2014-11-08T10:00:00\n"
     ]
    }
   ],
   "source": [
    "#Expected key-value output format:\n",
    "#hour_with_most_spam\t\"2013-11-10T10:00:00\"\n",
    "\n",
    "#Additional key-value pairs are acceptable, as long as the hour_with_most_spam pair is correct.\n",
    "import csv\n",
    "import sys\n",
    "import re\n",
    "\n",
    "with open('output/part-00000','r') as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "lines_list = [line for line in lines]\n",
    "num_list = [line.split()[1] for line in lines]\n",
    "max_index = num_list.index(max(num_list))\n",
    "most_spam = lines_list[max_index]\n",
    "print(\"hour_with_most_spam\\t\" + most_spam.split()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) \n",
    "Find all comments associated with a username (the AUTHOR field). Return a JSON array of all comments associated with that username. (This should use the data from all 5 data files: Psy, KatyPerry, LMFAO, Eminem, Shakira) [11 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mapper.py\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%writefile mapper2.py\n",
    "#!/usr/bin/env python\n",
    "#Answer for mapper2.py\n",
    "import csv\n",
    "import sys\n",
    "import re\n",
    "\n",
    "lines = sys.stdin.readlines()\n",
    "csvreader = csv.reader(lines)\n",
    "header = next(csvreader)\n",
    "        \n",
    "items = [[row[1],row[3]] for row in csvreader if row[4]=='1']\n",
    "\n",
    "for item in items:\n",
    "    print(item[0]+'\\t'+item[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting reducer2.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile reducer2.py\n",
    "#!/usr/bin/env python\n",
    "#Answer for reducer2.py\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "\n",
    "input_pairs = sys.stdin.readlines()\n",
    "accumulator = defaultdict(lambda: [])\n",
    "\n",
    "for row in input_pairs:\n",
    "    key_value_pair = row.split('\\t',1)\n",
    "    if len(key_value_pair) != 2:\n",
    "        continue\n",
    "        \n",
    "    author = key_value_pair[0]\n",
    "    comment = key_value_pair[1]\n",
    "    accumulator[author].append(comment)\n",
    "\n",
    "for (key, value) in accumulator.items():\n",
    "    print(key + \"\\t\" + str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2666playboy\t[' Follow me on Instagram. _chris_cz  \\xef\\xbb\\xbf\\n']\n",
      "8-BitMusic\t['Hey guys! Im a 12 yr old music producer. I make chiptunes and 8bit music.  It would be wonderful if you checked out some of my 8bit remixes! I even  have a gangnamstyle 8bit remix if you would like to check that out ;)  Thanks!!\\n']\n",
      "Aaa Aaa\t['PLEASE SUBSCRIBE ME!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\\xef\\xbb\\xbf\\n']\n",
      "abdellah chafouai\t['Discover a beautiful song of A young Moroccan     http://www.linkbucks.com/AcN2g\\xef\\xbb\\xbf\\n']\n",
      "Abdinasir Omar\t['Great music anyway\\xef\\xbb\\xbf\\n']\n",
      "Adam Mudd\t['How are there 2 billion views and theres only 2 million people in the  world!?!?!?!! MULTIPLE ACCOUNTS!!!1111\\xef\\xbb\\xbf\\n']\n",
      "adam riyati\t[\"Hey guys check out my new channel and our first vid THIS IS US THE  MONKEYS!!! I'm the monkey in the white shirt,please leave a like comment  and please subscribe!!!!\\n\"]\n",
      "Adele Lupei\t['Is this the video that started the whole \"got my dick stuck in an elevator\"  excuse thing? \\xef\\xbb\\xbf\\n']\n",
      "Adrian Skalak\t['http://www.ermail.pl/dolacz/V3VeYGIN CLICK  http://www.ermail.pl/dolacz/V3VeYGIN  http://www.ermail.pl/dolacz/V3VeYGIN  http://www.ermail.pl/dolacz/V3VeYGIN  http://www.ermail.pl/dolacz/V3VeYGIN  http://www.ermail.pl/dolacz/V3VeYGIN  http://www.ermail.pl/dolacz/V3VeYGIN\\xef\\xbb\\xbf\\n']\n",
      "Agarra Mela\t['how does this video have 2,127,322,484 views if there are only 7 million  people on earth?\\xef\\xbb\\xbf\\n']\n",
      "ahmed khalifa\t['Hello all 29.24% earth population of the world, hope your having a great  day :)\\xef\\xbb\\xbf\\n']\n",
      "Aj Riberal\t['Lol...I dunno how this joke gets a lot of likes, but whatever. xD\\xef\\xbb\\xbf\\n']\n",
      "Akymonix\t['Made in china....\\xef\\xbb\\xbf\\n']\n",
      "Aleksaivan Neidert\t['PSY - GANGNAM STYLE (\\xea\\xb0\\x95\\xeb\\x82\\xa8\\xec\\x8a\\xa4\\xed\\x83\\x80\\xec\\x9d\\xbc) M/V: http://youtu.be/9bZkp7q19f0\\xef\\xbb\\xbf\\n']\n",
      "Alessandro leite\t['pls http://www10.vakinha.com.br/VaquinhaE.aspx?e=313327 help me get vip gun  cross fire al\\xef\\xbb\\xbf\\n']\n",
      "Alessio Siri\t['PSY - GANGNAM STYLE (\\xea\\xb0\\x95\\xeb\\x82\\xa8\\xec\\x8a\\xa4\\xed\\x83\\x80\\xec\\x9d\\xbc) M/V: http://youtu.be/9bZkp7q19f0\\xef\\xbb\\xbf\\n']\n",
      "Almighty Toffeebomb\t['Wow. Comments section on this still active. Not bad. Also 5277478 comments.  (Now 79)\\xef\\xbb\\xbf\\n']\n",
      "Alucard Hellsing\t['What Can i say....This Song He Just Change The World Completely... So good job PSY... (and your girls are awesome :))) )\\xef\\xbb\\xbf\\n']\n",
      "Ameenk Chanel\t['Free my apps get 1m crdits ! Just click on the link and download a app and  done!! \\xc2\\xb7 Link: https://m.freemyapps.com/share/url/5af506e1\\xef\\xbb\\xbf\\n']\n",
      "amine moha\t['please like : http://www.bubblews.com/news/9277547-peace-and-brotherhood\\xef\\xbb\\xbf\\n']\n",
      "Amir effect\t['Can somebody wake me up when we get to 3 billion views.\\xef\\xbb\\xbf\\n']\n",
      "Andr3wco7\t['I found out this song now\\xef\\xbb\\xbf\\n']\n",
      "Angek95\t['Check my channel, please!\\xef\\xbb\\xbf\\n']\n",
      "Angela Flemming\t['Still a very fun music video to watch! \\xef\\xbb\\xbf\\n']\n",
      "Angel\t[\"Hi there~I'm group leader of Angel, a rookie Korean pop group. We have four  members, Chanicka, Julie, Stephanie, and myself, Leah. Please feel free to  check out our channel and leave some feedback on our cover videos (:  criticism is welcome as we know we're not top notch singers so please come  leave some constructive feedback on our videos; we appreciate any chance to  improve before auditioning for a Korean management company. We plan on  auditioning for JYP, BigHit, Jellyfish, YG or SM. Thank you for taking time  out of your day to read this !\\xef\\xbb\\xbf\\n\"]\n",
      "Anthony1SV\t[\"Please do buy these new Christmas shirts! You can buy at any time before  December 4th and they are sold worldwide! Don't miss out:  http://teespring.com/treechristmas\\xef\\xbb\\xbf\\n\"]\n",
      "anthony Jennings\t['People Who Say That \"This Song Is Too Old Now, There\\'s No Point Of  Listening To It\" Suck. Just Stfu And Enjoy The Music. So, Your Mom Is Old  Too But You Still Listen To Her Right?....\\xef\\xbb\\xbf\\n']\n",
      "Archie Lewis\t['https://twitter.com/GBphotographyGB\\xef\\xbb\\xbf\\n']\n",
      "Arianna Leighton\t[\"Does anyone here use gift cards like Amazon, itunes, psn, google play,  itunes, or any other gift cards? Then you'll be happy to know you can get  free gift card codes for free from an amazing site. Here is a $50 itunes  gift card code XXBB5TCZHM39HVZD\\xef\\xbb\\xbf\\n\"]\n",
      "Ariel Baptista\t['http://www.ebay.com/itm/131338190916?ssPageName=STRK:MESELX:IT&amp;_trksid=p3984.m1555.l2649 \\xef\\xbb\\xbf\\n']\n",
      "ArioseRose\t[\"Don't mind me, I'm just checking what the views are up to : )\\xef\\xbb\\xbf\\n\"]\n",
      "Arrestme11\t['How stupid humanity is\\xef\\xbb\\xbf\\n']\n",
      "Arthur Teixeira\t['I wanted to know the name of the guy that dances at 00:58, anybody knows ?\\xef\\xbb\\xbf\\n']\n",
      "Artsi\t['Pls follow this channel!! http://www.twitch.tv/sevadus\\xef\\xbb\\xbf\\n']\n",
      "asd ad\t['psy=korean\\xef\\xbb\\xbf\\n']\n",
      "Backup Plus\t['Suscribe My Channel Please XD lol\\xef\\xbb\\xbf\\n']\n",
      "BaconBro HD\t['Subscribe ME!\\xef\\xbb\\xbf\\n']\n",
      "BeatBoxBaaa\t[\"Have you tried a new social network TSU? This new social network has a  special thing.You can share the posts as well as on fb and twitter and even  to'll get paid You can registr here:  https://www.tsu.co/WORLDWIDE_LIFE\\xef\\xbb\\xbf\\n\"]\n",
      "BeBe Burkey\t['and u should.d check my channel and tell me what I should do next!\\xef\\xbb\\xbf\\n']\n",
      "Ben Stalker\t['GANGMAN STY- *D-D-D-D-D-D--DROP THE BASS!!*\\xef\\xbb\\xbf\\n']\n",
      "Bert Dionne\t['The most liked video on YouTube...\\xef\\xbb\\xbf\\n']\n",
      "Bert Ernie\t['this jap is such a piece of shit. he is such a worthless fish head. i dont  know how any one likes this dumb untanlted gook. this isnt even fucken  music. this is so fucking sad that this is even such thing. people are so  fucked up.\\xef\\xbb\\xbf\\n']\n",
      "BIGMOFO Tonkatruck\t['just came to check the view count\\xef\\xbb\\xbf\\n']\n",
      "Bishwaroop Bhattacharjee\t['https://www.facebook.com/SchoolGeniusNITS/photos/ms.c.eJw9kVkOxDAMQm808h5z~;4sNjqP~_tHqBEuM69AQUp1Ih~_fPHgk5zLLsVdQv0ZUf0MB~;LnUJ~;ufTH4YoKfRxYts2zvrrp6qGtw67y~;L551h~;f7~_vlcZzRG8vGCTlPSD9ONGeWhj8~_GIbu~;S3lzMvY~;IQ2~;TwSfzz9WHn7JUSvHufpglQRZczl05fNPhaGeVb3x8yDmC6X~_~;jTcjnMho~;vfXWCjZyvWObihrnGx2ocjnG2PG1EvHXzyjD~_o3h~_RY6f57sPrnD2xV~;~_BzszZ~;8~-.bps.a.390875584405933/391725794320912/?type=1&amp;theater \\xef\\xbb\\xbf\\n']\n",
      "Bizzle Sperq\t['https://www.facebook.com/nicushorbboy add mee &lt;3 &lt;3\\xef\\xbb\\xbf\\n']\n",
      "BlueYetiPlayz -Call Of Duty and More\t['subscribe to me for call of duty vids and give aways Goal-100 subs\\xef\\xbb\\xbf\\n']\n",
      "BmwManDexter\t['check out \"starlitnightsky\" channel to see epic videos\\xef\\xbb\\xbf\\n']\n",
      "Bob Kanowski\t['i turned it on mute as soon is i came on i just wanted to check the  views...\\xef\\xbb\\xbf\\n']\n",
      "Brandon Pryor\t['I dont even watch it anymore i just come here to check on 2 Billion or not\\xef\\xbb\\xbf\\n']\n",
      "Brandon Wilson\t['Why does a song like this have more views than Michael Jackson SMH\\xef\\xbb\\xbf\\n']\n",
      "Brotha B\t['Like getting Gift cards..but hate spending the cash.... Try Juno Wallet !!! At Juno Wallet you can earn money for gift cards such as ; Nike, Gamestop,  Amazon , Ebay Etc &amp; its easy  Earn money by doing simple task like watching videos..downloading apps &amp;  you can even earn money by inviting your friends to join...its free for  signup Sign up today &amp; use promo code BD3721315\\xef\\xbb\\xbf\\n']\n",
      "bruno jovao\t['LoL\\xef\\xbb\\xbf\\n']\n",
      "Caius Ballad\t['imagine if this guy put adsense on with all these views... u could pay ur  morgage\\xef\\xbb\\xbf\\n']\n",
      "cake cat\t['if you like roblox minecraft world of warcraft gta5 mario suscribe to my  channel\\xef\\xbb\\xbf\\n']\n",
      "Callum Barr\t['Subscribe to me plz plz plz plz plz plZ \\xef\\xbb\\xbf\\n']\n",
      "Carlos Thegamer\t['subscribe to my channel people :D\\xef\\xbb\\xbf\\n']\n",
      "Carmen Racasanu\t[\"How can this have 2 billion views when there's only me on the planet? LOL\\xef\\xbb\\xbf\\n\"]\n",
      "Chack Jason\t['OPPA &lt;3\\xef\\xbb\\xbf\\n']\n",
      "CHILD\t['WHY DOES THIS HAVE 2 BILLION VIEWS THIS SONG IS SO ANNOYING\\xef\\xbb\\xbf\\n']\n",
      "Chinsoman Films\t['Please subscribe to me\\xef\\xbb\\xbf\\n']\n",
      "Cody Tolleson\t[\"YouTube/codytolleson for awesome videos I'll subscribe back \\xef\\xbb\\xbf\\n\"]\n",
      "Connor Groom\t['sub me if you dont like the song\\xef\\xbb\\xbf\\n']\n",
      "Cony\t['You should check my channel for Funny VIDEOS!!\\xef\\xbb\\xbf\\n']\n",
      "Cool Ong\t['The Guy in the yellow suit kinda looks like Jae-suk \\xef\\xbb\\xbf\\n']\n",
      "crestpee\t['now its 1,884,034,783 views! pls. comment the view count the next hour :P\\xef\\xbb\\xbf\\n']\n",
      "Cromwell John Pascual\t['WAT DA FUCK THIS THE MOST VIEWED VIDEO IN YOUTUBE!\\xef\\xbb\\xbf\\n']\n",
      "CronicleFPS\t[\"Check me out I'm all about gaming \\xef\\xbb\\xbf\\n\"]\n",
      "Crooked Gaming\t['I made a gaming channel (Unique right?) :L Angry Minecraft!\\xef\\xbb\\xbf\\n']\n",
      "css403\t['i am 2,126,492,636 viewer :D\\xef\\xbb\\xbf\\n']\n",
      "CustomerService GM\t['https://www.facebook.com/pages/Mathster-WP/1495323920744243?ref=hl\\xef\\xbb\\xbf\\n']\n",
      "Dana Matich\t[\"Hey guys! Check this out: Kollektivet - Don't be slappin' my penis!  I  think that they deserve much more credit than they receive.\\xef\\xbb\\xbf\\n\"]\n",
      "Daniel Istrati\t['Can anyone sub to my channel? :D\\xef\\xbb\\xbf\\n']\n",
      "Dave X\t['....subscribe......  ......to my........  .....channel.......\\xef\\xbb\\xbf\\n']\n",
      "David Bell\t['the most viewed youtube video of all time?\\xef\\xbb\\xbf\\n']\n",
      "David Boček\t['https://www.change.org/p/facebook-twitter-youtube-do-not-censor-julien-blanc \\xef\\xbb\\xbf\\n']\n",
      "derrick lawson\t['https://www.facebook.com/FUDAIRYQUEEN?pnref=story\\xef\\xbb\\xbf\\n']\n",
      "Detroit Red Wings\t['http://www.gofundme.com/gvr7xg\\xef\\xbb\\xbf\\n']\n",
      "Diana Roque\t['THIS HAS MORE VIEWS THAN QUEEN AND MICHAEL JACKSON, 2 BILLION views omg\\xef\\xbb\\xbf\\n']\n",
      "Didier Drogba\t['http://www.twitch.tv/jaroadc come follow and watch my stream!\\xef\\xbb\\xbf\\n']\n",
      "diego acosta\t[\"If I get 100 subscribers, I will summon Freddy Mercury's ghost to whipe  from the face of earth One Direction and Miley Cirus.\\xef\\xbb\\xbf\\n\"]\n",
      "diego mogrovejo\t[\"I don't now why I'm watching this in 2014\\xef\\xbb\\xbf\\n\"]\n",
      "Digital Media Butterfly\t['The most watched video on YouTube is Psy\\xe2\\x80\\x99s \\xe2\\x80\\x9cGangnam Style\\xe2\\x80\\x9d, with 2.1  billion views. PSY - GANGNAM STYLE (\\xea\\xb0\\x95\\xeb\\x82\\xa8\\xec\\x8a\\xa4\\xed\\x83\\x80\\xec\\x9d\\xbc) M/V\\xef\\xbb\\xbf\\n']\n",
      "DirtySouthFlorida3\t['Subscribe to me i subscribe back!!!! Plus i have a nice ass lol\\xef\\xbb\\xbf\\n']\n",
      "Doris Chew\t['The little PSY is suffering Brain Tumor and only has 6 more months to live.  Please pray to him and the best lucks.\\xef\\xbb\\xbf\\n']\n",
      "Dovydas Baranauskas\t['https://www.tsu.co/Aseris get money here !\\xef\\xbb\\xbf\\n']\n",
      "DropItLikeItsSloth\t['just came here to check the views :P\\xef\\xbb\\xbf\\n']\n",
      "DropShotSk8r\t['Came here to check the views, goodbye.\\xef\\xbb\\xbf\\n']\n",
      "DylsFS\t['Hi guys my name is Dylan and I do IRL football videos I have 1030  subscribers and I think you guys would like my content so come check it out  and if you do subscribe!\\xef\\xbb\\xbf\\n']\n",
      "Dymetex\t['OMG this oldspice spraytan party commercial omg....i\\'m sitting here \"NO  this isn\\'t a real thing is it? OMG\" \\xef\\xbb\\xbf\\n']\n",
      "Eanna Cusack\t['Im just to check how much views it has\\xef\\xbb\\xbf\\n']\n",
      "Eddie Murphy\t['LOL this shit never gets old\\xef\\xbb\\xbf\\n']\n",
      "ElepticRage\t['sub my channel for no reason -_-\\xef\\xbb\\xbf\\n']\n",
      "Elieo Cardiopulmonary\t[\"im sorry for the spam but My name is Jenny. I go to high school where  everyone dresses fashionable but for me I don't because i need money to buy  cute clothes. I have low self esteem . I live with my dad. my mom passed  away when i was 6 so i don't really have a mother figure. I have 2 brothers  who is older than me. Since they are boys they get the attention while i  just be alone. I really want to wear pretty clothes like the girls in my  school and get a boyfriend. i just can't be my self. im very quite and shy  at school because i don't have the confidence in myself to talk to someone.  i did have one friend name Caroline but she moved away so now im alone. if  you could donate some money to me it would be great. i don't care about  expensive brand ill just shop at walmart because they have pretty clothes.  also i wanna get my nails done at a salon . i see alot of girls have these  french tips. i never had my nail did at a salon before i will really  appreciate if i can and get my hair curled too. http://www.gofundme.com/dressprettyonce thanks omg please.\\xef\\xbb\\xbf\\n\"]\n",
      "ElNino Melendez\t['me shaking my sexy ass on my channel enjoy ^_^ \\xef\\xbb\\xbf\\n']\n",
      "Emerson Zanol Zanol\t['need money?Enjoy https://www.tsu.co/emerson_zanol\\xef\\xbb\\xbf\\n']\n",
      "Emily Hamilton\t['This has had over 2 billion views.  Holy shit.\\xef\\xbb\\xbf\\n']\n",
      "eSkiip\t['This video will get to 2 billion just because of people checking if it has  hit 2 billion yet.\\xef\\xbb\\xbf\\n']\n",
      "Eugene Kalinin\t['The projects After Effects, Music, Foto, Web sites and another you can find  and buy here  http://audiojungle.net/user/EugeneKalinin/portfolio?ref=EugeneKalinin\\xef\\xbb\\xbf\\n']\n",
      "Evgeny Murashkin\t['just for test I have to say murdev.com\\n']\n",
      "fab life\t['plz check out fablife / welcome to fablife for diys and challenges so plz  subscribe thx!\\xef\\xbb\\xbf\\n']\n",
      "FaceTheFacts\t['You know a song sucks dick when you need to use google translate to know  what the fuck its saying!\\xef\\xbb\\xbf\\n']\n",
      "fad lad\t['http://www.amazon.co.uk/gp/offer-listing/B00ECVF93G/sr=8-2/qid=1415297812/ref=olp_tab_refurbished?ie=UTF8&amp;condition=refurbished&amp;qid=1415297812&amp;sr=8-2 \\xef\\xbb\\xbf\\n']\n",
      "전광용\t['Fantastic!\\xef\\xbb\\xbf\\n']\n",
      "fastestghost\t['The first comment is chuck norrus ovbiously :D\\xef\\xbb\\xbf\\n']\n",
      "FatPocketsTv\t['Search \"Chubbz Dinero - Ready Or Not \" Thanks \\xef\\xbb\\xbf\\n']\n",
      "ferleck ferles\t['Subscribe to my channel \\xef\\xbb\\xbf\\n']\n",
      "firo mota\t['please subscribe i am a new youtuber and need help please subscribe and i  will subscribe back :D hoppa HOPPA GaNgAm StYlE\\xef\\xbb\\xbf\\n']\n",
      "Francisco Nora\t['please like :D https://premium.easypromosapp.com/voteme/19924/616375350\\xef\\xbb\\xbf\\n']\n",
      "Freddie Barton\t[\"CHECK MY CHANNEL FOR MY NEW SONG 'STATIC'!! YOU'LL LOVE IT!!\\xef\\xbb\\xbf\\n\"]\n",
      "Fun&amp;Hacks\t['Subscribe to me for free Android games, apps.. \\xef\\xbb\\xbf\\n']\n",
      "funtimekid1199\t[\"http://www.twitch.tv/tareko100 Follow him on twitch and enter the keyword  !5800 and you'll have a chance of winning a really nice and expensive gun  for csgo that you can sell on the steam market\\xef\\xbb\\xbf\\n\"]\n",
      "Gaming 101\t[\"The funny thing is, 1,700,000,000 of the views are spam bots. I mean c'mon  2 BILLION views? BS!\\xef\\xbb\\xbf\\n\"]\n",
      "Gaming and Stuff PRO\t[\"Hello! Do you like gaming, art videos, scientific experiments, tutorials,  lyrics videos, and much, much more of that? If you do please check out our  channel and subscribe to it, we've just started, but soon we hope we will  be able to cover all of our expectations... You can also check out what  we've got so far!\\xef\\xbb\\xbf\\n\"]\n",
      "Gaming Land\t['5 milions comentars and 2 bilion views\\xef\\xbb\\xbf\\n']\n",
      "Gema LR\t[\"With the korean girl more slut and bitch : Hyuna :'33\\xef\\xbb\\xbf\\n\"]\n",
      "Ghazi Rizvi\t['http://www.bing.com/explore/rewards?PUBL=REFERAFRIEND&amp;CREA=RAW&amp;rrid=_0f9fa8aa-243a-5c2f-c349-ede05ea397ca Bing rewards, earn free money. AND NO U CANT GET UR VIRUS IN BLUE!\\xef\\xbb\\xbf\\n']\n",
      "Giang Nguyen\t['More... http://www.sunfrogshirts.com/Sunglass-World.html?24398\\xef\\xbb\\xbf\\n', 'https://www.facebook.com/teeLaLaLa\\xef\\xbb\\xbf\\n']\n",
      "Gianpaolo T\t['Wow 23 min ago\\xef\\xbb\\xbf\\n']\n",
      "Gio D.\t['Dumb Guy: Why is there 2 billion views when there are 7 million people on  earth??? Also, I know what 1+1 equals! 1+1=1! I am a smartie pants\\xef\\xbb\\xbf\\n']\n",
      "Gloria Garcia\t['subscribe to itz recaps and above diddle\\xef\\xbb\\xbf\\n']\n",
      "Goran Theboss\t['https://www.surveymonkey.com/s/CVHMKLT\\xef\\xbb\\xbf\\n']\n",
      "GsMega\t['watch?v=vtaRGgvGtWQ   Check this out .\\xef\\xbb\\xbf\\n']\n",
      "||GuitarZ||\t['CHECK OUT MY CHANNEL\\n']\n",
      "Haley Harmicar\t[\"9 year olds be like, 'How does this have 2 billion views when there are  only 3 people in the world'\\xef\\xbb\\xbf\\n\"]\n",
      "HamzaMurt | Advanced Warefare | Lets Play!\t['SUB 4 SUB PLEASE LIKE THIS COMMENT I WANT A SUCCESFULL YOUTUBE SO PPLEASE LIKE THIS  COMMENT AND SUBSCRIBE IT ONLY TAKES 10 SECONDS PLEASE IF YOU SUBSCRIBE ILL  SUBSCRIBE BACK THANKS\\xef\\xbb\\xbf\\n']\n",
      "Harrys Edits\t[\"if i reach 100 subscribers i will go round in public pouring a bucket of  ice water over people and then running away acting like it wasn't me! like  so people can see!!\\xef\\xbb\\xbf\\n\"]\n",
      "HarveyIsTheBoss\t[\"You gotta say its funny. well not 2 billion worth funny but still. It  clicked and everything went uphill. At least you don't have JB's shit on  #1.\\xef\\xbb\\xbf\\n\"]\n",
      "Holly\t['Follow me on Twitter @mscalifornia95\\xef\\xbb\\xbf\\n']\n",
      "Hollz C\t[\"I'm watching this in 2014\\xef\\xbb\\xbf\\n\"]\n",
      "Huckyduck\t['Hey subscribe to me\\xef\\xbb\\xbf\\n']\n",
      "hunter braddock\t['For all of the little kidz out there there is Like 7 to 8 Billon people on  earth NOT 7 to 8 MILLON.Get you facts straight before posting comments.\\xef\\xbb\\xbf\\n']\n",
      "ii Trollercopter\t[' Hey everyone!! I have just started my first YT channel i would be grateful  if some of you peoples could check out my first clip in BF4! and give me  some advice on how my video was and how i could improve it. ALSO be sure to  go check out the about to see what Im all about. Thanks for your time :) .  and to haters... You Hate, I WIN\\xef\\xbb\\xbf\\n']\n",
      "iKap Taz\t['Follow 4 Follow                           @ VaahidMustafic Like 4 Like \\xef\\xbb\\xbf\\n']\n",
      "Imprezzi Vidzz\t['My videos are half way decent, check them out if you want.\\xef\\xbb\\xbf\\n']\n",
      "Ink Video Shorts\t[\"Hey come check us out were new on youtube let us know what you think and  don't forget to subscribe thanks.\\xef\\xbb\\xbf\\n\"]\n",
      "InterGaming\t['everyones back lool this is almost 3 years old and people are still hear!  xD\\xef\\xbb\\xbf\\n']\n",
      "Isuzu\t['P E A C E  &amp;  L O V E  ! !\\xef\\xbb\\xbf\\n']\n",
      "Itss Synco\t['COME AND CHECK OUT MY NEW YOUTUBE CHHANEL, GOING TO BE POSTING DAILY!\\xef\\xbb\\xbf\\n']\n",
      "itzquiffer\t[\"C'mon 3 billion views!!!!!!!!\\xef\\xbb\\xbf\\n\"]\n",
      "Jackal James\t['https://soundcloud.com/jackal-and-james/wrap-up-the-night\\xef\\xbb\\xbf\\n']\n",
      "JackTheLad\t[\"Subscribe to me and I'll subscribe back!!!\\xef\\xbb\\xbf\\n\"]\n",
      "Jack ToadROXMK\t['Anybody who subscribes to me will get 10 subscribers\\xef\\xbb\\xbf\\n']\n",
      "JakeFrostMiner Palanca\t['DISLIKE.. Now one knows REAL music - ex. Enimen \\xef\\xbb\\xbf\\n']\n",
      "James Ridge\t['Check my first video out\\xef\\xbb\\xbf\\n']\n",
      "Jason Haddad\t['Hey, check out my new website!! This site is about kids stuff. kidsmediausa  . com\\n']\n",
      "Jason Provencal\t['Why dafuq is a Korean song so big in the USA. Does that mean we support  Koreans? Last time I checked they wanted to bomb us. \\xef\\xbb\\xbf\\n']\n",
      "jayson calzado\t['How can this music video get 2 billion views while im the only one watching  here on earth?????? lol\\xef\\xbb\\xbf\\n']\n",
      "JD COKE\t[\"It's so hard, sad :( iThat little child Actor HWANG MINOO dancing very  active child is suffering from brain tumor, only 6 month left for him .Hard  to believe .. Keep praying everyone for our future superstar.  #StrongLittlePsY #Fighting  SHARE EVERYONE PRAYING FOR HIM http://ygunited.com/2014/11/08/little-psy-from-the-has-brain-tumor-6-months-left-to-live/ \\xef\\xbb\\xbf\\n\"]\n",
      "Jdidk Loma\t['http://tankionline.com#friend=cd92db3f4 great game check it out!\\xef\\xbb\\xbf\\n']\n",
      "Jennifer Isaksen\t['Hahah, juyk! I allways laugh at the part 1:57.. LOL!\\xef\\xbb\\xbf\\n']\n",
      "Joaco Remis\t['Why the fuck this keeps updated? Comments :\"5 minutes ago\" Song: \"2 years and  4 months ago\"\\xef\\xbb\\xbf\\n']\n",
      "JoelR Ch\t['http://flipagram.com/f/LUkA1QMrhF\\xef\\xbb\\xbf\\n']\n",
      "Joengz\t['Check out my dubstep song \"Fireball\", made with Fruity Loops. I really took  time in it.  /watch?v=telOA6RIO8o\\xef\\xbb\\xbf\\n']\n",
      "johan gade\t[\"''Little Psy, only 5 months left.. Tumor in the head :( WE WILL MISS U &lt;3\\xef\\xbb\\xbf\\n\"]\n",
      "John Plaatt\t['On 0:02 u can see the camera man on his glasses....\\xef\\xbb\\xbf\\n']\n",
      "John Schmidt\t['why are they 5million comments when there is only 279.898 youtube Users.   5million fake account or PSY hacked youtube\\xef\\xbb\\xbf\\n']\n",
      "Jose Renteria\t['We are an EDM apparel company dedicated to bringing you music inspired  designs. Our clothing is perfect for any rave or music festival. We have  NEON crop tops, tank tops, t-shirts, v-necks and accessories! follow us on  Facebook or on instagraml for free giveaways news and more!! visit our site  at OnCueApparel\\xef\\xbb\\xbf\\n']\n",
      "josson 64\t['SUPER!!! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\\xef\\xbb\\xbf\\n']\n",
      "JP Jochem\t['Subscribe and like to me for more how to videos on minecraft!\\xef\\xbb\\xbf\\n']\n",
      "juanmanuel cespedes\t['i hate this music. fucking singer and every koean chainise ana US sucks me dick.\\xef\\xbb\\xbf\\n']\n",
      "Julius NM\t['Huh, anyway check out this you[tube] channel: kobyoshi02\\n']\n",
      "Juris Dumagan\t['I think he was drunk during this :) x)\\xef\\xbb\\xbf\\n']\n",
      "just a filthy kafir\t['Justin bieber = gay \\xef\\xbb\\xbf\\n']\n",
      "Ju`Wan Wright\t['Follow me on twitter &amp; IG : __killuminati94\\xef\\xbb\\xbf\\n']\n",
      "Kaiser Dragon\t['This is a weird video.\\xef\\xbb\\xbf\\n']\n",
      "Kaya Roberts\t['Admit it you just came here to check the number of viewers \\xef\\xbb\\xbf\\n']\n",
      "Kelsey bolley\t['Wow this video is the most viewed youtube video.. second that comes Justin  bieber- baby SMH WHAT HAS THE WORLD COME TO\\xef\\xbb\\xbf\\n']\n",
      "Kemal Kurtoglu\t['Im a RAPPER/SONGWRITER, check my video PLEASE..also subscribe for more  thanks :) tell me what you think.\\xef\\xbb\\xbf\\n']\n",
      "kenny clayton\t['#2012bitches\\xef\\xbb\\xbf\\n']\n",
      "khir abqari\t['they said this video are not deserve 2billion views , while they keep  visiting it to watch the viewer . \\xef\\xbb\\xbf\\n']\n",
      "Kiddy Kidso\t['Check my channel please! And listen to the best music ever :P\\xef\\xbb\\xbf\\n']\n",
      "Kincaid Liebenberg\t['PSY is a good guy\\xef\\xbb\\xbf\\n']\n",
      "King uzzy\t['Can we reach 3 billion views by December 2014? \\xef\\xbb\\xbf\\n']\n",
      "Kirill Nazarethian\t['2:05. Hahahahah \\xef\\xbb\\xbf\\n']\n",
      "Kirsty Brown\t['Plz subscribe to my channel and I will subscribe back xx\\xef\\xbb\\xbf\\n']\n",
      "Kitts Hausman\t[\"It's so funny it's awesomeness lol aaaaaaa sexy lada\\xf0\\x9f\\x98\\x82\\xef\\xbb\\xbf\\n\"]\n",
      "Kochos\t['i check back often to help reach 2x10^9 views and I avoid watching Baby\\xef\\xbb\\xbf\\n']\n",
      "KodysMan Dunt Know\t['https://www.tsu.co/KodysMan plz ^^\\xef\\xbb\\xbf\\n']\n",
      "Kyle Jaber\t[\"Check me out! I'm kyle. I rap so yeah \\xef\\xbb\\xbf\\n\"]\n",
      "lakis constantinou\t['PSY GOT LOTS  OF MONEY FROM YOUTUBE THAT HE GOT FROM 2 BILLION VIEWS THIS  IS THE MOST VIEWS IN THE WORLD :D\\xef\\xbb\\xbf\\n']\n",
      "Lars Zaadstra\t['Sub to my channel visuelgamingzNL I sub back\\xef\\xbb\\xbf\\n']\n",
      "LaunchPad Mad\t[\"Hello! I'm kind of new to Youtube, And soon i'm soon going to be making  Launchpad Video's! :D I would really appreciate if i got some subs before i  started so that people can spot me easily! I dont really care about hate  comments so dont bother -_-\\xef\\xbb\\xbf\\n\"]\n",
      "LBEProductions\t[\"Hey guys can you check my channel out plz. I do mine craft videos. Let's  shoot for 20 subs\\xef\\xbb\\xbf\\n\"]\n",
      "lebanonwarior1\t['Song name??\\xef\\xbb\\xbf\\n']\n",
      "Leonardo Baptista\t['http://www.avaaz.org/po/petition/Youtube_Corporation_Fox_Broadcasting_Company_Anular_os_strikes_no_Canal_Nostalgia/?cXPZpgb \\xef\\xbb\\xbf\\n']\n",
      "LEONARDO CAETANO\t['2 Billions in 2014\\n']\n",
      "Leonel Hernandez\t[' Something to dance to, even if your sad JUST dance!!   PSY - GANGNAM STYLE (\\xea\\xb0\\x95\\xeb\\x82\\xa8\\xec\\x8a\\xa4\\xed\\x83\\x80\\xec\\x9d\\xbc) M/V: http://youtu.be/9bZkp7q19f0\\xef\\xbb\\xbf\\n']\n",
      "Lindsay Wofford\t['What is he saying?!?!?!?!?!?!?!?$? \\xef\\xbb\\xbf\\n']\n",
      "Liu Chu Yi\t['I am so awesome and smart!!! Sucscribe to me!\\xef\\xbb\\xbf\\n']\n",
      "Living4Techno\t['marketglory . com/strategygame/andrijamatf earn real money from game\\n']\n",
      "Lone Twistt\t[\" Once you have started reading do not stop. If you do not subscribe to me  within one day you and you're entire family will die so if you want to stay  alive subscribe right now.\\xef\\xbb\\xbf\\n\"]\n",
      "Luat ha hpuoc\t['so crazy, over 2 billion views, not US, not Uk, its Korea republic, its  asia\\xef\\xbb\\xbf\\n']\n",
      "Lucas Trigo\t['WHATS UP EVERYONE!? :-) I Trying To Showcase My Talent To The World! I Have Over 3000 SUBSCRIBERS! I PROMISE! I Dont Suck! Please Spread My Covers Around, SUBSCRIBE &amp; Share! Thanks so much for all your support! Lucas Trigo -Stay Awesome! \\xef\\xbb\\xbf\\n']\n",
      "Lucky D.\t['http://hackfbaccountlive.com/?ref=4604617\\xef\\xbb\\xbf\\n']\n",
      "Luna Gamer Potter\t[' I hate this song! \\xef\\xbb\\xbf\\n']\n",
      "M7AMDksa\t['\\xe2\\x9d\\xa4\\xef\\xb8\\x8f \\xe2\\x9d\\xa4\\xef\\xb8\\x8f \\xe2\\x9d\\xa4\\xef\\xb8\\x8f \\xe2\\x9d\\xa4\\xef\\xb8\\x8f \\xe2\\x9d\\xa4\\xef\\xb8\\x8f\\xe2\\x9d\\xa4\\xef\\xb8\\x8f\\xe2\\x9d\\xa4\\xef\\xb8\\x8f\\xe2\\x9d\\xa4\\xef\\xb8\\x8f\\xef\\xbb\\xbf\\n']\n",
      "Malin Linford\t['Hey guys please check out my new Google+ page it has many funny pictures,  FunnyTortsPics  https://plus.google.com/112720997191206369631/post\\xef\\xbb\\xbf\\n']\n",
      "Markus Mairhofer\t['Hey, join me on ts\\xc5\\xab, a publishing platform where I share my content now:  http://tsu.co/MarkusMairhofer\\xef\\xbb\\xbf\\n']\n",
      "marye\t['Oppa! Yeah! Best Song!\\xef\\xbb\\xbf\\n']\n",
      "Mason Sieverding\t['Please check out my vidios\\xef\\xbb\\xbf\\n', 'Please check out my vidios guys\\xef\\xbb\\xbf\\n']\n",
      "Master Chief\t['when is this gonna hit 2 billion?\\xef\\xbb\\xbf\\n']\n",
      "MasterRobotTV\t['http://www.twitch.tv/zxlightsoutxz\\xef\\xbb\\xbf\\n']\n",
      "Mehmet Demirel\t['http://www.gcmforex.com/partners/aw.aspx?Task=JoinT2&amp;AffiliateID=9107\\xef\\xbb\\xbf\\n']\n",
      "Melissa Harmon\t['how is this shit still relevant \\xef\\xbb\\xbf\\n']\n",
      "Meth Lover\t['http://binbox.io/1FIRo#123\\xef\\xbb\\xbf\\n']\n",
      "MFkin PRXPHETZ\t['if you like raw talent, raw lyrics, straight real hip hop Everyone check my newest sound  Dizzy X - Got the Juice (Prod by. Drugs the Model Citizen)   COMMENT TELL ME WHAT YOU THINK  DONT BE LAZY!!!!  - 1/7 Prophetz\\xef\\xbb\\xbf\\n']\n",
      "Mia Aspinall\t['2 billion views, only 2 million shares\\xef\\xbb\\xbf\\n']\n",
      "michelle clough\t['2 BILLION!!!\\xef\\xbb\\xbf\\n']\n",
      "Milan George\t['thumbs up if u checked this video to see hw views it got\\xef\\xbb\\xbf\\n']\n",
      "mindaugux\t['why I dont see any comments but mine?:/\\xef\\xbb\\xbf\\n']\n",
      "Minecraft-Viasat\t['Check my channel\\xef\\xbb\\xbf\\n']\n",
      "MiningBip3\t['Check out pivot animations in my channel\\xef\\xbb\\xbf\\n']\n",
      "Monster Sifou\t['8 million likes xD even the subscribers not 8 million xD\\xef\\xbb\\xbf\\n']\n",
      "Monwar Sarkar\t['Please help me go here http://www.gofundme.com/littlebrother\\xef\\xbb\\xbf\\n']\n",
      "Moymoy Palaboy\t['This is the best, funny and viral video of history (youtube) THE TRUE\\xef\\xbb\\xbf\\n']\n",
      "MrBrunoExtreme\t['Suscribe my channel please\\xef\\xbb\\xbf\\n']\n",
      "MrTuizentfloot\t['This is the only video on youtube that get so much views just because we  want to see how much views it has. 1.000.000 every day, I mean, Most people  think a video is popular when it actually gets 1.000.000 views.\\xef\\xbb\\xbf\\n']\n",
      "MrValentinique\t['https://www.facebook.com/eeccon/posts/733949243353321?comment_id=734237113324534&amp;offset=0&amp;total_comments=74   please like frigea marius gabriel comment :D\\xef\\xbb\\xbf\\n']\n",
      "Muhd Hafiz\t['WORLD RECORD YOUTUBE VIDEO VIEWS !!!!!! XD\\xef\\xbb\\xbf\\n']\n",
      "nachopinca3901\t['Stupid people... this video doesnt have 2 billion visits. Have 2 thousands  millions\\xef\\xbb\\xbf\\n']\n",
      "nathan robson\t['If i reach 100 subscribers i will tazz my self and my friend\\xef\\xbb\\xbf\\n']\n",
      "Navin Surya\t['Please help me go to college guys! Thanks from the bottom of my heart.  https://www.indiegogo.com/projects/i-want-to-go-to-college--19/x/9082175\\xef\\xbb\\xbf\\n']\n",
      "Neely Nesley\t['Dance dance,,,,,Psy  http://www.reverbnation.com/msmarilynmiles\\xef\\xbb\\xbf\\n']\n",
      "Niggly Wiggly\t['Go to my channel if u want to see a fly getting burned alive\\xef\\xbb\\xbf\\n']\n",
      "Nikolay Tekuchev\t['This video is so cool, again and again!\\xef\\xbb\\xbf\\n']\n",
      "Noah François\t['Ahhh, 2 years ago....\\xef\\xbb\\xbf\\n']\n",
      "nobleMC | Minecraft, GFX and More!\t[\"If I get 300 subscribers by tomorrow I'll do a epic Hunger Games Video! \\xef\\xbb\\xbf\\n\"]\n",
      "no honesty\t['Still watching this 2 years later? \\xef\\xbb\\xbf\\n']\n",
      "none dies virgin life fucks us all\t[\"You think you're smart?        Headbutt your face.\\xef\\xbb\\xbf\\n\"]\n",
      "Norman Reid\t['Mix - PSY - GANGNAM STYLE (\\xea\\xb0\\x95\\xeb\\x82\\xa8\\xec\\x8a\\xa4\\xed\\x83\\x80\\xec\\x9d\\xbc) M/V: PSY - GANGNAM STYLE (\\xea\\xb0\\x95\\xeb\\x82\\xa8\\xec\\x8a\\xa4\\xed\\x83\\x80\\xec\\x9d\\xbc) M/V\\xef\\xbb\\xbf\\n']\n",
      "NstyIC Gold\t['Ching Ching ling long ding ring yaaaaaa Ganga sty FUCK YOU.\\xef\\xbb\\xbf\\n']\n",
      "NursePoison\t['I think this is now a place to promote channels in the comment section lol.\\xef\\xbb\\xbf\\n']\n",
      "OFFICIAL LEXIS\t[\"Hi everyone! Do you like music? Then why not check out my music channel.  The LEXIS band will be uploading their own songs and covers soon so don't  miss out. Please SUBSCRIBE too as it does help us out a lot. Just takes one  click. -&gt;\\xef\\xbb\\xbf\\n\"]\n",
      "Oh 1080s\t['Sub my channel!\\xef\\xbb\\xbf\\n']\n",
      "Oopsthenameistoolong Oh well\t['Like if you came here too see how many views this song has.\\xef\\xbb\\xbf\\n']\n",
      "OREOGAM3R\t[\"It's been back for quite a while now.\\n\"]\n",
      "O sábio das 7 eras\t['Please friend read my book and repass: http://www.4shared.com/web/preview/pdf/CjFofTxeba?\\xef\\xbb\\xbf\\n']\n",
      "OutrightIgnite\t['http://www.ebay.com/itm/171183229277?ssPageName=STRK:MESELX:IT&amp;_trksid=p3984.m1555.l2649 \\xef\\xbb\\xbf\\n', 'Show your AUBURN PRIDE HERE: http://www.teespring.com/tigermeathoodie\\xef\\xbb\\xbf\\n']\n",
      "OverSpace33\t['For Christmas Song visit my channel! ;)\\xef\\xbb\\xbf\\n']\n",
      "Owen Lai\t['just checking the views\\xef\\xbb\\xbf\\n']\n",
      "PacKmaN\t['check men out i put allot of effort into my music but unfortunatly not many  watch it\\xef\\xbb\\xbf\\n', 'hey again if you guys wouldnt mind chacking out my rap give it like and il  giver 3 of your vids a like\\xef\\xbb\\xbf\\n']\n",
      "Parssa Alimadad\t['Dear person reading this, You are beautiful and loving Have a great day\\xef\\xbb\\xbf\\n']\n",
      "Pat M\t['gofundme.com/grwmps\\xef\\xbb\\xbf\\n']\n",
      "Patrick Pernia\t['Limit sun exposure while driving. Eliminate the hassle of having to swing  the car visor between the windshield and window.  https://www.kickstarter.com/projects/733634264/visortwin\\xef\\xbb\\xbf\\n']\n",
      "Peter Johnson\t['Get free gift cards and pay pal money!\\xef\\xbb\\xbf\\n']\n",
      "Photo Editor\t['hi guys please my android photo editor download. thanks https://play.google.com/store/apps/details?id=com.butalabs.photo.editor\\xef\\xbb\\xbf\\n']\n",
      "Phuc Ly\t['go here to check the views :3\\xef\\xbb\\xbf\\n']\n",
      "PinkyThePuppyProductions\t['I am now going to voyage to the first comment...      Tell my family I loved them. \\xf0\\x9f\\x98\\xa2\\xef\\xbb\\xbf\\n']\n",
      "piwnugget\t['YOUTUBE MONEY !!!!!!!!!!!!!!!!!!!!!!!\\xef\\xbb\\xbf\\n']\n",
      "Praise Samuel\t[\"2 billion views wow not even baby by justin beibs has that much he doesn't  deserve a capitalized name\\xef\\xbb\\xbf\\n\"]\n",
      "Prim N.\t['Just coming to check if people are still viewing this video. And  apparently, they still do.\\xef\\xbb\\xbf\\n']\n",
      "ProsGamerOnly\t['hi guys check my youtube channel\\xef\\xbb\\xbf\\n']\n",
      "pro stomper\t['guys please subscribe me to help my channel grow please guys\\xef\\xbb\\xbf\\n']\n",
      "Pro Video\t['subscribe to me :) \\xef\\xbb\\xbf\\n']\n",
      "Puppy Lover5614\t[\"I hav absolutely no idea what he's saying. Is it even a language?\\xef\\xbb\\xbf\\n\"]\n",
      "Rancy Gaming\t['What free gift cards? Go here  http://www.swagbucks.com/p/register?rb=13017194\\xef\\xbb\\xbf\\n']\n",
      "Ray Benich\t['The first billion viewed this because they thought it was really cool, the  other billion and a half came to see how stupid the first billion were...\\xef\\xbb\\xbf\\n']\n",
      "restlesswikiinfo\t['If I knew Korean, this would be even funnier. At least a bit at the end was  in English, but was spoken quite rapidly.\\xef\\xbb\\xbf\\n']\n",
      "richardex8\t['Why does this video have so many views? Because asian things are awesome and non-asian countries are jelly so they  try to learn from asia by looking at this video d:\\xef\\xbb\\xbf\\n']\n",
      "Ripazha Gaming\t['http://hackfbaccountlive.com/?ref=5242575\\xef\\xbb\\xbf\\n']\n",
      "Robin Delwiche\t['I still to this day wonder why this video is so popular ?? illuminati  confirmed ??\\xef\\xbb\\xbf\\n']\n",
      "ROB YSF\t['reminds me of this song https://soundcloud.com/popaegis/wrenn-almond-eyes\\xef\\xbb\\xbf\\n']\n",
      "roflcopter2110\t['http://thepiratebay.se/torrent/6381501/Timothy_Sykes_Collection\\xef\\xbb\\xbf\\n']\n",
      "rolle54100\t['how can there be 2.124.821.694 views, when im the only person alive after  the zombie apocalypse - greetings, spoderman :)\\xef\\xbb\\xbf\\n']\n",
      "Romeo Sweeney\t['this has so many views\\xef\\xbb\\xbf\\n']\n",
      "Ruddy Tapia\t['get GWAR to play 2015 superbowl  http://www.change.org/petitions/the-national-football-league-allow-gwar-to-perform-the-2015-super-bowl-halftime-show#share \\xef\\xbb\\xbf\\n']\n",
      "sagar basnet\t['The population of world is more than 7 billion\\xef\\xbb\\xbf\\n']\n",
      "sahil samal\t['1 millioon dislikesssssssssssssssssssssssssssssssss.............\\xef\\xbb\\xbf\\n']\n",
      "Salim Tayara\t['if your like drones, plz subscribe to Kamal Tayara. He takes videos with  his drone that are absolutely beautiful.\\xef\\xbb\\xbf\\n']\n",
      "Sean Deko\t['2,000,000,000 out of 7,000,000,000 people in the would saw this video just  in 2 years and yeat i only get 2 words out of the hole song\\xef\\xbb\\xbf\\n']\n",
      "Sean Ortiz\t['Incmedia.org where the truth meets you.\\xef\\xbb\\xbf\\n']\n",
      "Serkan Kaya\t['http://hackfbaccountlive.com/?ref=4436607  psy news off\\xc4\\xb1cal \\xef\\xbb\\xbf\\n']\n",
      "Sev3617\t[\"How did THIS Video in all of YouTube get this many views and likes? Why  Gangnam style? I don't have a problem with it, i just don't understand the  phenomena behind it, it's just like any other random music video out  there. \\xef\\xbb\\xbf\\n\"]\n",
      "Sigaraya Nesora\t['The girl in the train who was dancing, her outfit was so fucking sexy, but  the huge turn-off was she lacked eyebrows D:\\xef\\xbb\\xbf\\n']\n",
      "Spencer Clark\t['If you pause at 1:39 at the last millisecond you can see that that chick is  about to laugh. Takes a few tries.\\xef\\xbb\\xbf\\n']\n",
      "Squir3\t['http://woobox.com/33gxrf/brt0u5 FREE CS GO!!!!\\xef\\xbb\\xbf\\n']\n",
      "SRK FAN\t['2 Billion Views For This Piece Of Shit... ~ A R E ~ Y O U ~ K I D D I N G ~ M E ~\\xef\\xbb\\xbf\\n']\n",
      "StarBlade34 OverLord\t['Lol this youtuber (officialpsy) is getting so much money lol\\xef\\xbb\\xbf\\n']\n",
      "Starfire003\t['OMG 2/7 People watched this video because there are 7 billion people in the  world and 2 billion watched this\\xef\\xbb\\xbf\\n']\n",
      "Stefano Albanese\t['http://www.guardalo.org/best-of-funny-cats-gatti-pazzi-e-divertenti-2013-5287/100000415527985/ \\xef\\xbb\\xbf\\n']\n",
      "Stronzo Chicheritr\t['prehistoric song..has been\\xef\\xbb\\xbf\\n']\n",
      "Stuart Mcdonald\t['FOLLOW MY COMPANY ON TWITTER  thanks.  https://twitter.com/TheWaxedHatCo\\xef\\xbb\\xbf\\n']\n",
      "StuntmanGaming\t['Behold the most viewed youtube video in the history of ever\\xef\\xbb\\xbf\\n']\n",
      "Super Cot\t['1 million dislikes!EPIC FAIL(ready for you fanboys)\\xef\\xbb\\xbf\\n']\n",
      "Susan Jay\t['Enough with the whole \"how does this have two billion views if there\\'s only  7 million on the planet\" we get it. You\\'re joking. It\\'s not funny anymore.\\xef\\xbb\\xbf\\n']\n",
      "Tabby Ghani\t['I remember when everyone was obsessed with Gangnam Style \\xf0\\x9f\\x98\\x97\\xef\\xbb\\xbf\\n']\n",
      "Tasha Lucius\t['2 billion....Coming soon\\xef\\xbb\\xbf\\n']\n",
      "Tedi Foto\t['What my gangnam style\\xef\\xbb\\xbf\\n']\n",
      "Tee Tee\t['Loool nice song funny how no one understands (me) and we love it\\xef\\xbb\\xbf\\n']\n",
      "Thanh Phong\t['OMG over 2 billion views!\\xef\\xbb\\xbf\\n']\n",
      "The Bibliophile Flautist\t['Hey everyone, I am a new channel and will post videos of book reviews and  music on the flute. Please subscribe if you would enjoy that. Thanks!\\xef\\xbb\\xbf\\n']\n",
      "TheHariiiii\t['-----&gt;&gt;&gt;&gt;  https://www.facebook.com/video.php?v=10200253113705769&amp;set=vb.201470069872822&amp;type=3&amp;permPage=1  &lt;--------\\xef\\xbb\\xbf\\n']\n",
      "TheInfectedDoge Gameplay\t['most viewed video in the world\\xef\\xbb\\xbf\\n']\n",
      "TheLegitBroz\t['The Funny Thing Is That this song was made in 2009 but it took 2 years to  get to america.\\xef\\xbb\\xbf\\n']\n",
      "The O'dowd Crowd\t['Come and watch my video it is called the odowd crowd zombie movie part 1 \\xef\\xbb\\xbf\\n']\n",
      "TheRogueScorpion\t['MANY MEMORIES...........\\xef\\xbb\\xbf\\n']\n",
      "The Silent Troll Defuser HD\t['Hey guys can you check my YouTube channel I know you hate comments like  this one but I promise if you check my videos it will be entertaining I do  Shotgun Montages,Ninja Defuse Montages and Trolling please guys can you  check them out and thanks have a good day!!!!!!!\\xef\\xbb\\xbf\\n']\n",
      "The Silhouette\t['Most viewed video on youtube...daaaaaaaaaaannng those views can almost  dominate the entire...china...\\xef\\xbb\\xbf\\n']\n",
      "TheUploadaddict\t['subscribe like comment\\xef\\xbb\\xbf\\n']\n",
      "thevlogmasters Vlog, Challenges en nog veel meer!\t['\\xe2\\x96\\xac\\xe2\\x96\\xac\\xe2\\x96\\xac\\xe2\\x96\\xac\\xe2\\x96\\xac\\xe2\\x96\\xac\\xe2\\x96\\xac\\xe2\\x96\\xac\\xe2\\x96\\xac\\xe2\\x96\\xac\\xe0\\xae\\x9c\\xdb\\xa9\\xdb\\x9e\\xdb\\xa9\\xe0\\xae\\x9c\\xe2\\x96\\xac\\xe2\\x96\\xac\\xe2\\x96\\xac\\xe2\\x96\\xac\\xe2\\x96\\xac\\xe2\\x96\\xac\\xe2\\x96\\xac\\xe2\\x96\\xac \\xef\\xbc\\xa4\\xef\\xbc\\xa1\\xef\\xbc\\xad\\xef\\xbc\\xae \\xef\\xbc\\xb4\\xef\\xbc\\xa8\\xef\\xbc\\xa9\\xef\\xbc\\xb3 \\xef\\xbc\\xa3\\xef\\xbc\\xaf\\xef\\xbc\\xad\\xef\\xbc\\xad\\xef\\xbc\\xa5\\xef\\xbc\\xae\\xef\\xbc\\xb4 \\xef\\xbc\\xa9\\xef\\xbc\\xb3 \\xef\\xbc\\xa6\\xef\\xbc\\xa1\\xef\\xbc\\xae\\xef\\xbc\\xa3Y \\xe2\\x96\\xac\\xe2\\x96\\xac\\xe2\\x96\\xac\\xe2\\x96\\xac\\xe2\\x96\\xac\\xe2\\x96\\xac\\xe2\\x96\\xac\\xe2\\x96\\xac\\xe2\\x96\\xac\\xe2\\x96\\xac\\xe0\\xae\\x9c\\xdb\\xa9\\xdb\\x9e\\xdb\\xa9\\xe0\\xae\\x9c\\xe2\\x96\\xac\\xe2\\x96\\xac\\xe2\\x96\\xac\\xe2\\x96\\xac\\xe2\\x96\\xac\\xe2\\x96\\xac\\xe2\\x96\\xac\\xe2\\x96\\xac\\xef\\xbb\\xbf\\n']\n",
      "This Is Really Not Lois Arceo\t[\"NEW GOAL!   3,000,000!  Let's go for it!\\xef\\xbb\\xbf\\n\"]\n",
      "Thomas sea\t['please throw a sub on my channel\\xef\\xbb\\xbf\\n']\n",
      "ThoseFour KidsYaay\t['2 billion for this shit?\\xef\\xbb\\xbf\\n']\n",
      "Thuan Lai Tran\t['This is getting old.........\\xef\\xbb\\xbf\\n']\n",
      "TIGERIO_\t['EHI GUYS CAN YOU SUBSCRIBE IN MY CHANNEL? I AM A NEW YOUTUBER AND I PLAY  MINECRAFT THANKS GUYS!... SUBSCRIBE!\\xef\\xbb\\xbf\\n']\n",
      "TLouX music\t['Add me here...https://www.facebook.com/TLouXmusic\\xef\\xbb\\xbf\\n']\n",
      "Tofik Miedzyń\t['https://www.facebook.com/tofikmiedzynB/photos/a.1496273723978022.1073741828.1496241863981208/1498561870415874/?type=1&amp;theater \\xef\\xbb\\xbf\\n']\n",
      "tom hawksbee\t['It is 0 zero\\xef\\xbb\\xbf\\n']\n",
      "Tom Hosford\t[\"To everyone joking about how he hacked to get 2 billion views because  there's a certain amount of people or whatever,  He actually did buy views.\\xef\\xbb\\xbf\\n\"]\n",
      "Tony K Frazier\t['http://ubuntuone.com/40beUutVu2ZKxK4uTgPZ8K\\xef\\xbb\\xbf\\n']\n",
      "Tornike Noniashvili\t['subscribe my chanel\\xef\\xbb\\xbf\\n']\n",
      "trespasser4000\t['This song never gets old love it.\\xef\\xbb\\xbf\\n']\n",
      "Tyrek Sings\t['CHECK MY CHANNEL OUT PLEASE. I DO SINGING COVERS\\xef\\xbb\\xbf\\n']\n",
      "UKz DoleSnacher\t['Remove This video its wank\\xef\\xbb\\xbf\\n']\n",
      "unknown\t['\\xf0\\x9f\\x98\\xab\\xf0\\x9f\\x98\\x93\\xf0\\x9f\\x98\\x8f\\xf0\\x9f\\x98\\xaa\\xf0\\x9f\\x98\\x94\\xf0\\x9f\\x98\\x96\\xf0\\x9f\\x98\\x8c\\xf0\\x9f\\x98\\xad\\xf0\\x9f\\x98\\x8e\\xf0\\x9f\\x98\\x9a\\xf0\\x9f\\x98\\x98\\xf0\\x9f\\x98\\x99\\xf0\\x9f\\x98\\x97\\xf0\\x9f\\x98\\x8b\\xf0\\x9f\\x98\\x9d\\xf0\\x9f\\x98\\x9c\\xf0\\x9f\\x98\\x9b\\xf0\\x9f\\x98\\x8d\\xf0\\x9f\\x98\\x92\\xf0\\x9f\\x98\\x9e\\xf0\\x9f\\x98\\xb7\\xf0\\x9f\\x98\\xb6\\xf0\\x9f\\x98\\xb5\\xf0\\x9f\\x98\\xb3\\xf0\\x9f\\x98\\xb2\\xf0\\x9f\\x98\\xb1\\xf0\\x9f\\x98\\x9f\\xf0\\x9f\\x98\\xb0\\xf0\\x9f\\x98\\xa9\\xf0\\x9f\\x98\\xa8\\xf0\\x9f\\x98\\xa7\\xf0\\x9f\\x98\\xa6\\xf0\\x9f\\x98\\xa5\\xf0\\x9f\\x98\\xa4\\xf0\\x9f\\x98\\xa3\\xf0\\x9f\\x98\\xae\\xf0\\x9f\\x98\\xb4\\xf0\\x9f\\x98\\xa2\\xf0\\x9f\\x98\\xa1\\xf0\\x9f\\x98\\xa0\\xf0\\x9f\\x98\\xac\\xf0\\x9f\\x98\\x95\\xf0\\x9f\\x98\\x91\\xf0\\x9f\\x98\\x90\\xf0\\x9f\\x98\\xaf\\xf0\\x9f\\x98\\x89\\xf0\\x9f\\x98\\x88\\xf0\\x9f\\x98\\x87\\xf0\\x9f\\x98\\x86\\xf0\\x9f\\x98\\x85\\xf0\\x9f\\x98\\x84\\xf0\\x9f\\x98\\x83\\xf0\\x9f\\x98\\x82\\xf0\\x9f\\x98\\x81\\xf0\\x9f\\x98\\x80\\xf0\\x9f\\x98\\x8a\\xe2\\x98\\xba  every single types of face on earth\\xef\\xbb\\xbf\\n']\n",
      "Uroš Slemenjak\t[\"People, here is a new network like FB...you register also free, the  difference is only that you get paid for sharing, commenting and liking  posts and so one...don't waste your time on fb for sharing and not being  paid!! Register here to make also money with your everyday posts!!  https://www.tsu.co/slema13 Wellcome to everyone! ;)\\xef\\xbb\\xbf\\n\"]\n",
      "Vepi road to TIx\t['Still the best. :D\\xef\\xbb\\xbf\\n']\n",
      "VIP 2NEXO\t['OPPA GANGNAM STYLE!!!\\xef\\xbb\\xbf\\n']\n",
      "Viperas Lord\t['www.marketglory.com/strategygame/lordviperas\\xef\\xbb\\xbf\\n']\n",
      "virgie natividad\t['969,210 dislikes like dislike themselves\\xef\\xbb\\xbf\\n']\n",
      "Vitor Belliny\t['2.126.521.750  views!!!!!!!!!!!!!!!!!\\xef\\xbb\\xbf\\n']\n",
      "Warrdrew\t[\"I'm here to check the views.. holy shit\\xef\\xbb\\xbf\\n\"]\n",
      "Wert Walleet\t['This song is great there are 2,127,315,950 views wow\\xef\\xbb\\xbf\\n']\n",
      "Wilfredo Latorre\t[\"Hey I think I know what where dealing with here!!!! I have some theories of  how this could've gotten 2billion hits!! 1. This was mabey made in korea and its realy popular there so they were  stuck watching this over and over again. 2. Over 2billion people have access to the Internet, including youtube, and  the numbers are rising, by 2017 half of the populatoin will be connected. 3. Hackers In Korea may have loved it so much they rised it to 2billion  hits to make it more popular.  4. The song was featured in a just dance game, on multiple mp3s, and been  seen on concerts and even on new years eve event in 2012, so just by seeing  those you mabey adding more hits to this video. 5. You are complaining to much on how the heck this has 2b hits.\\xef\\xbb\\xbf\\n\"]\n",
      "witsnow roxiie\t['We pray for you Little Psy \\xe2\\x99\\xa1\\xef\\xbb\\xbf\\n']\n",
      "World327RS\t[\"SUBSCRIBE TO ME AND I'LL SUBSCRIBE TO YOU! (Must like - cZFcxsn0jnQ) \\xef\\xbb\\xbf\\n\"]\n",
      "Wumrogue lite\t['https://www.facebook.com/pages/Brew-Crew-2014/134470083389909 Like this  facebook-page! Chance to win an Iphone 5S!\\xef\\xbb\\xbf\\n']\n",
      "x Judda\t['We get it, you came here for the views... \\xef\\xbb\\xbf\\n']\n",
      "xMasterGGx\t['2,124923004 wiews... wow\\xef\\xbb\\xbf\\n']\n",
      "xSparkShark\t[\"Screw this Chinese crap i dont even understand what he is saying. Why isn't  he speaking English like everyone should?\\xef\\xbb\\xbf\\n\"]\n",
      "xxxTheMikeTxxx\t['Will this song ever reach 7 Billion Views?\\xef\\xbb\\xbf\\n']\n",
      "Yabbamita DBH\t[\"If the shitty Chinese Government didn't block YouTube over there, there'd  be close to 3 billion views right now. \\xef\\xbb\\xbf\\n\"]\n",
      "Yeung Marvin\t['Haha its so funny to see the salt of westerners that top views of youtube  goes to video they dont even understand, keep the salt up!\\xef\\xbb\\xbf\\n']\n",
      "YOU ARE NOW WASTING SECONDS OF YOUR LIFE BY READING THIS LONG STUPID NAME WHICH MAKES NO SENSE!\t['this comment is wrong\\xef\\xbb\\xbf\\n']\n",
      "YoungBrothersRecords\t[\"Please give us a chance and check out the new music video on our channel!  You won't be disappointed.\\xef\\xbb\\xbf\\n\"]\n",
      "Young Hittaz\t['everyone please come check our newest song in memories of Martin Luther  King Jr.\\xef\\xbb\\xbf\\n']\n",
      "Young IncoVEVO\t['Check out my Music Videos! Fuego - U LA LA Remix  hyperurl.co/k6a5xt\\xef\\xbb\\xbf\\n', 'Check out my Music Videos! and PLEASE SUBSCRIBE!!!! Fuego - U LA LA Remix  hyperurl.co/k6a5xt\\xef\\xbb\\xbf\\n']\n",
      "zakaia ziko\t['follower please https://www.facebook.com/lists/161620527267482\\xef\\xbb\\xbf\\n']\n",
      "zhichao wang\t['i think about 100 millions of the views come from people who only wanted to  check the views\\xef\\xbb\\xbf\\n']\n",
      "Zielimeek21\t[\"I'm only checking the views\\xef\\xbb\\xbf\\n\"]\n",
      "ZodexHD\t['look at my channel i make minecraft pe lets play \\xef\\xbb\\xbf\\n']\n",
      "Александр Федоров\t['Look at the pictures, if not difficult http://image2you.ru/48051/1340524/        http://image2you.ru/48051/1340523/          http://image2you.ru/48051/1340522/ http://image2you.ru/48051/1340521/             http://image2you.ru/48051/1340520/       http://image2you.ru/48051/1340519/  http://image2you.ru/48051/1340518/            http://image2you.ru/48051/1340517/          http://image2you.ru/48051/1340504/ http://image2you.ru/48051/1340503/              http://image2you.ru/48051/1340502/            http://image2you.ru/48051/1340500/ http://image2you.ru/48051/1340499/        http://image2you.ru/48051/1340494/             http://image2you.ru/48051/1340493/ http://image2you.ru/48051/1340492/        http://image2you.ru/48051/1340491/           http://image2you.ru/48051/1340490/ http://image2you.ru/48051/1340489/             http://image2you.ru/48051/1340488/\\xef\\xbb\\xbf\\n']\n",
      "Михаил Панкратов\t['There is one video on my channel about my brother...\\xef\\xbb\\xbf\\n']\n",
      "Никита Безухов\t['https://www.indiegogo.com/projects/cleaning-the-pan--2    please halp me  with my project\\xef\\xbb\\xbf\\n']\n",
      "Олег Пась\t['Plizz withing my channel \\xef\\xbb\\xbf\\n']\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "chmod a+x mapper2.py reducer2.py\n",
    "cat Youtube01-Psy.csv | ./mapper2.py | ./reducer2.py | sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hadoop switched to standalone mode.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenJDK Server VM warning: You have loaded library /opt/hadoop-2.8.5/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.\n",
      "It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.\n",
      "18/12/10 09:52:29 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "18/12/10 09:52:30 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id\n",
      "18/12/10 09:52:30 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=\n",
      "18/12/10 09:52:30 INFO jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "18/12/10 09:52:30 INFO mapred.FileInputFormat: Total input files to process : 5\n",
      "18/12/10 09:52:30 INFO mapreduce.JobSubmitter: number of splits:5\n",
      "18/12/10 09:52:30 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local560112486_0001\n",
      "18/12/10 09:52:31 INFO mapred.LocalDistributedCacheManager: Localized file:/home/comp6235/Notebooks/cw2/mapper2.py as file:/tmp/hadoop-comp6235/mapred/local/1544435551007/mapper2.py\n",
      "18/12/10 09:52:31 INFO mapred.LocalDistributedCacheManager: Localized file:/home/comp6235/Notebooks/cw2/reducer2.py as file:/tmp/hadoop-comp6235/mapred/local/1544435551008/reducer2.py\n",
      "18/12/10 09:52:31 INFO mapreduce.Job: The url to track the job: http://localhost:8080/\n",
      "18/12/10 09:52:31 INFO mapreduce.Job: Running job: job_local560112486_0001\n",
      "18/12/10 09:52:31 INFO mapred.LocalJobRunner: OutputCommitter set in config null\n",
      "18/12/10 09:52:31 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapred.FileOutputCommitter\n",
      "18/12/10 09:52:31 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "18/12/10 09:52:31 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "18/12/10 09:52:32 INFO mapred.LocalJobRunner: Waiting for map tasks\n",
      "18/12/10 09:52:32 INFO mapred.LocalJobRunner: Starting task: attempt_local560112486_0001_m_000000_0\n",
      "18/12/10 09:52:32 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "18/12/10 09:52:32 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "18/12/10 09:52:32 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "18/12/10 09:52:32 INFO mapred.MapTask: Processing split: file:/home/comp6235/Notebooks/cw2/Youtube04-Eminem.csv:0+82896\n",
      "18/12/10 09:52:32 INFO mapred.MapTask: numReduceTasks: 1\n",
      "18/12/10 09:52:32 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "18/12/10 09:52:32 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "18/12/10 09:52:32 INFO mapred.MapTask: soft limit at 83886080\n",
      "18/12/10 09:52:32 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "18/12/10 09:52:32 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "18/12/10 09:52:32 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "18/12/10 09:52:32 INFO streaming.PipeMapRed: PipeMapRed exec [/home/comp6235/Notebooks/cw2/././mapper2.py]\n",
      "18/12/10 09:52:32 INFO Configuration.deprecation: mapred.work.output.dir is deprecated. Instead, use mapreduce.task.output.dir\n",
      "18/12/10 09:52:32 INFO Configuration.deprecation: map.input.start is deprecated. Instead, use mapreduce.map.input.start\n",
      "18/12/10 09:52:32 INFO Configuration.deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap\n",
      "18/12/10 09:52:32 INFO Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id\n",
      "18/12/10 09:52:32 INFO Configuration.deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id\n",
      "18/12/10 09:52:32 INFO Configuration.deprecation: mapred.local.dir is deprecated. Instead, use mapreduce.cluster.local.dir\n",
      "18/12/10 09:52:32 INFO Configuration.deprecation: map.input.file is deprecated. Instead, use mapreduce.map.input.file\n",
      "18/12/10 09:52:32 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords\n",
      "18/12/10 09:52:32 INFO Configuration.deprecation: map.input.length is deprecated. Instead, use mapreduce.map.input.length\n",
      "18/12/10 09:52:32 INFO Configuration.deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id\n",
      "18/12/10 09:52:32 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name\n",
      "18/12/10 09:52:32 INFO Configuration.deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition\n",
      "18/12/10 09:52:32 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "18/12/10 09:52:32 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "18/12/10 09:52:32 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "18/12/10 09:52:32 INFO streaming.PipeMapRed: Records R/W=454/1\n",
      "18/12/10 09:52:32 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "18/12/10 09:52:32 INFO streaming.PipeMapRed: mapRedFinished\n",
      "18/12/10 09:52:32 INFO mapred.LocalJobRunner: \n",
      "18/12/10 09:52:32 INFO mapred.MapTask: Starting flush of map output\n",
      "18/12/10 09:52:32 INFO mapred.MapTask: Spilling map output\n",
      "18/12/10 09:52:32 INFO mapred.MapTask: bufstart = 0; bufend = 58487; bufvoid = 104857600\n",
      "18/12/10 09:52:32 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26212588(104850352); length = 1809/6553600\n",
      "18/12/10 09:52:32 INFO mapred.MapTask: Finished spill 0\n",
      "18/12/10 09:52:32 INFO mapred.Task: Task:attempt_local560112486_0001_m_000000_0 is done. And is in the process of committing\n",
      "18/12/10 09:52:32 INFO mapred.LocalJobRunner: Records R/W=454/1\n",
      "18/12/10 09:52:32 INFO mapred.Task: Task 'attempt_local560112486_0001_m_000000_0' done.\n",
      "18/12/10 09:52:32 INFO mapred.Task: Final Counters for attempt_local560112486_0001_m_000000_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=218157\n",
      "\t\tFILE: Number of bytes written=576956\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=454\n",
      "\t\tMap output records=453\n",
      "\t\tMap output bytes=58487\n",
      "\t\tMap output materialized bytes=59576\n",
      "\t\tInput split bytes=106\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=453\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=66\n",
      "\t\tTotal committed heap usage (bytes)=137433088\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=82896\n",
      "18/12/10 09:52:32 INFO mapred.LocalJobRunner: Finishing task: attempt_local560112486_0001_m_000000_0\n",
      "18/12/10 09:52:32 INFO mapred.LocalJobRunner: Starting task: attempt_local560112486_0001_m_000001_0\n",
      "18/12/10 09:52:32 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "18/12/10 09:52:32 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "18/12/10 09:52:32 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "18/12/10 09:52:32 INFO mapred.MapTask: Processing split: file:/home/comp6235/Notebooks/cw2/Youtube05-Shakira.csv:0+72706\n",
      "18/12/10 09:52:32 INFO mapred.MapTask: numReduceTasks: 1\n",
      "18/12/10 09:52:32 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "18/12/10 09:52:32 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "18/12/10 09:52:32 INFO mapred.MapTask: soft limit at 83886080\n",
      "18/12/10 09:52:32 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "18/12/10 09:52:32 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "18/12/10 09:52:32 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "18/12/10 09:52:32 INFO mapreduce.Job: Job job_local560112486_0001 running in uber mode : false\n",
      "18/12/10 09:52:32 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "18/12/10 09:52:32 INFO streaming.PipeMapRed: PipeMapRed exec [/home/comp6235/Notebooks/cw2/././mapper2.py]\n",
      "18/12/10 09:52:32 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "18/12/10 09:52:32 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "18/12/10 09:52:32 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "18/12/10 09:52:33 INFO streaming.PipeMapRed: Records R/W=371/1\n",
      "18/12/10 09:52:33 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "18/12/10 09:52:33 INFO streaming.PipeMapRed: mapRedFinished\n",
      "18/12/10 09:52:33 INFO mapred.LocalJobRunner: \n",
      "18/12/10 09:52:33 INFO mapred.MapTask: Starting flush of map output\n",
      "18/12/10 09:52:33 INFO mapred.MapTask: Spilling map output\n",
      "18/12/10 09:52:33 INFO mapred.MapTask: bufstart = 0; bufend = 47004; bufvoid = 104857600\n",
      "18/12/10 09:52:33 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26212920(104851680); length = 1477/6553600\n",
      "18/12/10 09:52:33 INFO mapred.MapTask: Finished spill 0\n",
      "18/12/10 09:52:33 INFO mapred.Task: Task:attempt_local560112486_0001_m_000001_0 is done. And is in the process of committing\n",
      "18/12/10 09:52:33 INFO mapred.LocalJobRunner: Records R/W=371/1\n",
      "18/12/10 09:52:33 INFO mapred.Task: Task 'attempt_local560112486_0001_m_000001_0' done.\n",
      "18/12/10 09:52:33 INFO mapred.Task: Final Counters for attempt_local560112486_0001_m_000001_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=291416\n",
      "\t\tFILE: Number of bytes written=624875\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=371\n",
      "\t\tMap output records=370\n",
      "\t\tMap output bytes=47004\n",
      "\t\tMap output materialized bytes=47887\n",
      "\t\tInput split bytes=107\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=370\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=20\n",
      "\t\tTotal committed heap usage (bytes)=184619008\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=72706\n",
      "18/12/10 09:52:33 INFO mapred.LocalJobRunner: Finishing task: attempt_local560112486_0001_m_000001_0\n",
      "18/12/10 09:52:33 INFO mapred.LocalJobRunner: Starting task: attempt_local560112486_0001_m_000002_0\n",
      "18/12/10 09:52:33 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "18/12/10 09:52:33 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "18/12/10 09:52:33 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "18/12/10 09:52:33 INFO mapred.MapTask: Processing split: file:/home/comp6235/Notebooks/cw2/Youtube03-LMFAO.csv:0+64419\n",
      "18/12/10 09:52:33 INFO mapred.MapTask: numReduceTasks: 1\n",
      "18/12/10 09:52:33 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "18/12/10 09:52:33 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "18/12/10 09:52:33 INFO mapred.MapTask: soft limit at 83886080\n",
      "18/12/10 09:52:33 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "18/12/10 09:52:33 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "18/12/10 09:52:33 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "18/12/10 09:52:33 INFO streaming.PipeMapRed: PipeMapRed exec [/home/comp6235/Notebooks/cw2/././mapper2.py]\n",
      "18/12/10 09:52:33 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "18/12/10 09:52:33 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "18/12/10 09:52:33 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "18/12/10 09:52:33 INFO streaming.PipeMapRed: Records R/W=439/1\n",
      "18/12/10 09:52:33 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "18/12/10 09:52:33 INFO streaming.PipeMapRed: mapRedFinished\n",
      "18/12/10 09:52:33 INFO mapred.LocalJobRunner: \n",
      "18/12/10 09:52:33 INFO mapred.MapTask: Starting flush of map output\n",
      "18/12/10 09:52:33 INFO mapred.MapTask: Spilling map output\n",
      "18/12/10 09:52:33 INFO mapred.MapTask: bufstart = 0; bufend = 35831; bufvoid = 104857600\n",
      "18/12/10 09:52:33 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26212648(104850592); length = 1749/6553600\n",
      "18/12/10 09:52:33 INFO mapred.MapTask: Finished spill 0\n",
      "18/12/10 09:52:33 INFO mapred.Task: Task:attempt_local560112486_0001_m_000002_0 is done. And is in the process of committing\n",
      "18/12/10 09:52:33 INFO mapred.LocalJobRunner: Records R/W=439/1\n",
      "18/12/10 09:52:33 INFO mapred.Task: Task 'attempt_local560112486_0001_m_000002_0' done.\n",
      "18/12/10 09:52:33 INFO mapred.Task: Final Counters for attempt_local560112486_0001_m_000002_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=356388\n",
      "\t\tFILE: Number of bytes written=661682\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=439\n",
      "\t\tMap output records=438\n",
      "\t\tMap output bytes=35831\n",
      "\t\tMap output materialized bytes=36775\n",
      "\t\tInput split bytes=105\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=438\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=68\n",
      "\t\tTotal committed heap usage (bytes)=169488384\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=64419\n",
      "18/12/10 09:52:33 INFO mapred.LocalJobRunner: Finishing task: attempt_local560112486_0001_m_000002_0\n",
      "18/12/10 09:52:33 INFO mapred.LocalJobRunner: Starting task: attempt_local560112486_0001_m_000003_0\n",
      "18/12/10 09:52:33 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "18/12/10 09:52:33 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "18/12/10 09:52:33 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "18/12/10 09:52:33 INFO mapred.MapTask: Processing split: file:/home/comp6235/Notebooks/cw2/Youtube02-KatyPerry.csv:0+64279\n",
      "18/12/10 09:52:33 INFO mapred.MapTask: numReduceTasks: 1\n",
      "18/12/10 09:52:33 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "18/12/10 09:52:33 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "18/12/10 09:52:33 INFO mapred.MapTask: soft limit at 83886080\n",
      "18/12/10 09:52:33 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "18/12/10 09:52:33 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "18/12/10 09:52:33 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "18/12/10 09:52:33 INFO streaming.PipeMapRed: PipeMapRed exec [/home/comp6235/Notebooks/cw2/././mapper2.py]\n",
      "18/12/10 09:52:33 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "18/12/10 09:52:33 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "18/12/10 09:52:33 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "18/12/10 09:52:33 INFO streaming.PipeMapRed: Records R/W=351/1\n",
      "18/12/10 09:52:33 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "18/12/10 09:52:33 INFO streaming.PipeMapRed: mapRedFinished\n",
      "18/12/10 09:52:33 INFO mapred.LocalJobRunner: \n",
      "18/12/10 09:52:33 INFO mapred.MapTask: Starting flush of map output\n",
      "18/12/10 09:52:33 INFO mapred.MapTask: Spilling map output\n",
      "18/12/10 09:52:33 INFO mapred.MapTask: bufstart = 0; bufend = 43828; bufvoid = 104857600\n",
      "18/12/10 09:52:33 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26213000(104852000); length = 1397/6553600\n",
      "18/12/10 09:52:33 INFO mapred.MapTask: Finished spill 0\n",
      "18/12/10 09:52:33 INFO mapred.Task: Task:attempt_local560112486_0001_m_000003_0 is done. And is in the process of committing\n",
      "18/12/10 09:52:33 INFO mapred.LocalJobRunner: Records R/W=351/1\n",
      "18/12/10 09:52:33 INFO mapred.Task: Task 'attempt_local560112486_0001_m_000003_0' done.\n",
      "18/12/10 09:52:33 INFO mapred.Task: Final Counters for attempt_local560112486_0001_m_000003_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=421220\n",
      "\t\tFILE: Number of bytes written=706363\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=351\n",
      "\t\tMap output records=350\n",
      "\t\tMap output bytes=43828\n",
      "\t\tMap output materialized bytes=44649\n",
      "\t\tInput split bytes=109\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=350\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=39\n",
      "\t\tTotal committed heap usage (bytes)=219598848\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=64279\n",
      "18/12/10 09:52:33 INFO mapred.LocalJobRunner: Finishing task: attempt_local560112486_0001_m_000003_0\n",
      "18/12/10 09:52:33 INFO mapred.LocalJobRunner: Starting task: attempt_local560112486_0001_m_000004_0\n",
      "18/12/10 09:52:33 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "18/12/10 09:52:33 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "18/12/10 09:52:33 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "18/12/10 09:52:33 INFO mapred.MapTask: Processing split: file:/home/comp6235/Notebooks/cw2/Youtube01-Psy.csv:0+57438\n",
      "18/12/10 09:52:33 INFO mapred.MapTask: numReduceTasks: 1\n",
      "18/12/10 09:52:33 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "18/12/10 09:52:33 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "18/12/10 09:52:33 INFO mapred.MapTask: soft limit at 83886080\n",
      "18/12/10 09:52:33 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "18/12/10 09:52:33 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "18/12/10 09:52:33 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "18/12/10 09:52:33 INFO streaming.PipeMapRed: PipeMapRed exec [/home/comp6235/Notebooks/cw2/././mapper2.py]\n",
      "18/12/10 09:52:33 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "18/12/10 09:52:33 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "18/12/10 09:52:33 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "18/12/10 09:52:33 INFO streaming.PipeMapRed: Records R/W=351/1\n",
      "18/12/10 09:52:33 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "18/12/10 09:52:33 INFO streaming.PipeMapRed: mapRedFinished\n",
      "18/12/10 09:52:33 INFO mapred.LocalJobRunner: \n",
      "18/12/10 09:52:33 INFO mapred.MapTask: Starting flush of map output\n",
      "18/12/10 09:52:33 INFO mapred.MapTask: Spilling map output\n",
      "18/12/10 09:52:33 INFO mapred.MapTask: bufstart = 0; bufend = 36895; bufvoid = 104857600\n",
      "18/12/10 09:52:33 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26213000(104852000); length = 1397/6553600\n",
      "18/12/10 09:52:33 INFO mapred.MapTask: Finished spill 0\n",
      "18/12/10 09:52:33 INFO mapred.Task: Task:attempt_local560112486_0001_m_000004_0 is done. And is in the process of committing\n",
      "18/12/10 09:52:34 INFO mapred.LocalJobRunner: Records R/W=351/1\n",
      "18/12/10 09:52:34 INFO mapred.Task: Task 'attempt_local560112486_0001_m_000004_0' done.\n",
      "18/12/10 09:52:34 INFO mapred.Task: Final Counters for attempt_local560112486_0001_m_000004_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=479211\n",
      "\t\tFILE: Number of bytes written=744073\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=351\n",
      "\t\tMap output records=350\n",
      "\t\tMap output bytes=36895\n",
      "\t\tMap output materialized bytes=37678\n",
      "\t\tInput split bytes=103\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=350\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=22\n",
      "\t\tTotal committed heap usage (bytes)=137437184\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=57438\n",
      "18/12/10 09:52:34 INFO mapred.LocalJobRunner: Finishing task: attempt_local560112486_0001_m_000004_0\n",
      "18/12/10 09:52:34 INFO mapred.LocalJobRunner: map task executor complete.\n",
      "18/12/10 09:52:34 INFO mapred.LocalJobRunner: Waiting for reduce tasks\n",
      "18/12/10 09:52:34 INFO mapred.LocalJobRunner: Starting task: attempt_local560112486_0001_r_000000_0\n",
      "18/12/10 09:52:34 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "18/12/10 09:52:34 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "18/12/10 09:52:34 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "18/12/10 09:52:34 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@53061c\n",
      "18/12/10 09:52:34 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=363285696, maxSingleShuffleLimit=90821424, mergeThreshold=239768576, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "18/12/10 09:52:34 INFO reduce.EventFetcher: attempt_local560112486_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "18/12/10 09:52:34 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local560112486_0001_m_000003_0 decomp: 44645 len: 44649 to MEMORY\n",
      "18/12/10 09:52:34 INFO reduce.InMemoryMapOutput: Read 44645 bytes from map-output for attempt_local560112486_0001_m_000003_0\n",
      "18/12/10 09:52:34 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 44645, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->44645\n",
      "18/12/10 09:52:34 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local560112486_0001_m_000000_0 decomp: 59572 len: 59576 to MEMORY\n",
      "18/12/10 09:52:34 INFO reduce.InMemoryMapOutput: Read 59572 bytes from map-output for attempt_local560112486_0001_m_000000_0\n",
      "18/12/10 09:52:34 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 59572, inMemoryMapOutputs.size() -> 2, commitMemory -> 44645, usedMemory ->104217\n",
      "18/12/10 09:52:34 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local560112486_0001_m_000001_0 decomp: 47883 len: 47887 to MEMORY\n",
      "18/12/10 09:52:34 INFO reduce.InMemoryMapOutput: Read 47883 bytes from map-output for attempt_local560112486_0001_m_000001_0\n",
      "18/12/10 09:52:34 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 47883, inMemoryMapOutputs.size() -> 3, commitMemory -> 104217, usedMemory ->152100\n",
      "18/12/10 09:52:34 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local560112486_0001_m_000004_0 decomp: 37674 len: 37678 to MEMORY\n",
      "18/12/10 09:52:34 INFO reduce.InMemoryMapOutput: Read 37674 bytes from map-output for attempt_local560112486_0001_m_000004_0\n",
      "18/12/10 09:52:34 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 37674, inMemoryMapOutputs.size() -> 4, commitMemory -> 152100, usedMemory ->189774\n",
      "18/12/10 09:52:34 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local560112486_0001_m_000002_0 decomp: 36771 len: 36775 to MEMORY\n",
      "18/12/10 09:52:34 INFO reduce.InMemoryMapOutput: Read 36771 bytes from map-output for attempt_local560112486_0001_m_000002_0\n",
      "18/12/10 09:52:34 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 36771, inMemoryMapOutputs.size() -> 5, commitMemory -> 189774, usedMemory ->226545\n",
      "18/12/10 09:52:34 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning\n",
      "18/12/10 09:52:34 INFO mapred.LocalJobRunner: 5 / 5 copied.\n",
      "18/12/10 09:52:34 INFO reduce.MergeManagerImpl: finalMerge called with 5 in-memory map-outputs and 0 on-disk map-outputs\n",
      "18/12/10 09:52:34 INFO mapred.Merger: Merging 5 sorted segments\n",
      "18/12/10 09:52:34 INFO mapred.Merger: Down to the last merge-pass, with 5 segments left of total size: 226461 bytes\n",
      "18/12/10 09:52:34 INFO reduce.MergeManagerImpl: Merged 5 segments, 226545 bytes to disk to satisfy reduce memory limit\n",
      "18/12/10 09:52:34 INFO reduce.MergeManagerImpl: Merging 1 files, 226541 bytes from disk\n",
      "18/12/10 09:52:34 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce\n",
      "18/12/10 09:52:34 INFO mapred.Merger: Merging 1 sorted segments\n",
      "18/12/10 09:52:34 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 226518 bytes\n",
      "18/12/10 09:52:34 INFO mapred.LocalJobRunner: 5 / 5 copied.\n",
      "18/12/10 09:52:34 INFO streaming.PipeMapRed: PipeMapRed exec [/home/comp6235/Notebooks/cw2/././reducer2.py]\n",
      "18/12/10 09:52:34 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "18/12/10 09:52:34 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\n",
      "18/12/10 09:52:34 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "18/12/10 09:52:34 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "18/12/10 09:52:34 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "18/12/10 09:52:34 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "18/12/10 09:52:34 INFO streaming.PipeMapRed: Records R/W=1961/1\n",
      "18/12/10 09:52:34 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "18/12/10 09:52:34 INFO streaming.PipeMapRed: mapRedFinished\n",
      "18/12/10 09:52:34 INFO mapred.Task: Task:attempt_local560112486_0001_r_000000_0 is done. And is in the process of committing\n",
      "18/12/10 09:52:34 INFO mapred.LocalJobRunner: 5 / 5 copied.\n",
      "18/12/10 09:52:34 INFO mapred.Task: Task attempt_local560112486_0001_r_000000_0 is allowed to commit now\n",
      "18/12/10 09:52:34 INFO output.FileOutputCommitter: Saved output of task 'attempt_local560112486_0001_r_000000_0' to file:/home/comp6235/Notebooks/cw2/output2/_temporary/0/task_local560112486_0001_r_000000\n",
      "18/12/10 09:52:34 INFO mapred.LocalJobRunner: Records R/W=1961/1 > reduce\n",
      "18/12/10 09:52:34 INFO mapred.Task: Task 'attempt_local560112486_0001_r_000000_0' done.\n",
      "18/12/10 09:52:34 INFO mapred.Task: Final Counters for attempt_local560112486_0001_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=932477\n",
      "\t\tFILE: Number of bytes written=1231981\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=1797\n",
      "\t\tReduce shuffle bytes=226565\n",
      "\t\tReduce input records=1961\n",
      "\t\tReduce output records=1797\n",
      "\t\tSpilled Records=1961\n",
      "\t\tShuffled Maps =5\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=5\n",
      "\t\tGC time elapsed (ms)=6\n",
      "\t\tTotal committed heap usage (bytes)=137437184\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=261367\n",
      "18/12/10 09:52:34 INFO mapred.LocalJobRunner: Finishing task: attempt_local560112486_0001_r_000000_0\n",
      "18/12/10 09:52:34 INFO mapred.LocalJobRunner: reduce task executor complete.\n",
      "18/12/10 09:52:34 INFO mapreduce.Job:  map 100% reduce 100%\n",
      "18/12/10 09:52:34 INFO mapreduce.Job: Job job_local560112486_0001 completed successfully\n",
      "18/12/10 09:52:34 INFO mapreduce.Job: Counters: 30\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=2698869\n",
      "\t\tFILE: Number of bytes written=4545930\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=1966\n",
      "\t\tMap output records=1961\n",
      "\t\tMap output bytes=222045\n",
      "\t\tMap output materialized bytes=226565\n",
      "\t\tInput split bytes=530\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=1797\n",
      "\t\tReduce shuffle bytes=226565\n",
      "\t\tReduce input records=1961\n",
      "\t\tReduce output records=1797\n",
      "\t\tSpilled Records=3922\n",
      "\t\tShuffled Maps =5\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=5\n",
      "\t\tGC time elapsed (ms)=221\n",
      "\t\tTotal committed heap usage (bytes)=986013696\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=341738\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=261367\n",
      "18/12/10 09:52:34 INFO streaming.StreamJob: Output directory: output2\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "#Hadoop command to run the map reduce.\n",
    "rm -rf output2\n",
    "\n",
    "hadoop-standalone-mode.sh\n",
    "\n",
    "hadoop jar $HADOOP_HOME/share/hadoop/tools/lib/hadoop-streaming-*.jar \\\n",
    "-files mapper2.py,reducer2.py   \\\n",
    "-input Youtube01-Psy.csv,Youtube02-KatyPerry.csv,Youtube03-LMFAO.csv,Youtube04-Eminem.csv,Youtube05-Shakira.csv   \\\n",
    "-mapper ./mapper2.py  \\\n",
    "-reducer ./reducer2.py \\\n",
    "-output output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Expected key-value output format:\n",
    "#John Smith\t[\"Comment 1\", \"Comment 2\", \"Comment 3\", \"etc.\"]\n",
    "#Jane Doe\t[\"Comment 1\", \"Comment 2\", \"Comment 3\", \"etc.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Derek Moya\t['You guys should check out this EXTRAORDINARY website called MONEYGQ.COM .   You can make money online and start working from home today as I am!   I am making over $3,000+ per month at MONEYGQ.COM !   Visit MONEYGQ.COM and check it out!  Why does the wood photograph the husky breath? When does the act retain the delightful system? The rhythm fabricates the scintillating harbor.\\n', 'You guys should check out this EXTRAORDINARY website called MONEYGQ.COM .   You can make money online and start working from home today as I am!   I am making over $3,000+ per month at MONEYGQ.COM !   Visit MONEYGQ.COM and check it out!  Why does the innocent woman prioritize the desire? The flight searchs the sad polish. When does the tax zip the omniscient record?\\n', 'You guys should check out this EXTRAORDINARY website called MONEYGQ.COM .   You can make money online and start working from home today as I am!   I am making over $3,000+ per month at MONEYGQ.COM !   Visit MONEYGQ.COM and check it out!  When does the flimsy slip facilitate the manager? How does the noise set goals the anxious regret? How does the actually loss retrieve the smile?\\n', 'You guys should check out this EXTRAORDINARY website called MONEYGQ.COM .   You can make money online and start working from home today as I am!   I am making over $3,000+ per month at MONEYGQ.COM !   Visit MONEYGQ.COM and check it out!  The metal drews the reflective effect. Why does the expansion intervene the hilarious bit? The sneeze witnesss the smoke.\\n', 'You guys should check out this EXTRAORDINARY website called MONEYGQ.COM .   You can make money online and start working from home today as I am!   I am making over $3,000+ per month at MONEYGQ.COM !   Visit MONEYGQ.COM and check it out!  Why does the fragile swim enlist the person? How does the ice audit the frequent son? The fantastic chance describes the rate.\\n']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import sys\n",
    "import re\n",
    "\n",
    "username = 'Derek Moya'\n",
    "\n",
    "def search_comments_by_username(username):\n",
    "    with open('output2/part-00000','r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    item_dict = {}\n",
    "    for line in lines:\n",
    "        line = line.split('\\t',1)\n",
    "        item_dict[line[0]] = line[1]\n",
    "    \n",
    "    print(username + '\\t' + item_dict[username])\n",
    "    \n",
    "search_comments_by_username(username)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
